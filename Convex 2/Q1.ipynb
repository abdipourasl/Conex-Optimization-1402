{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQPNR08rglpt"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<h1>Convex Optimization Project #2<h1>\n",
        "Amin Abdipour 401133011</h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1"
      ],
      "metadata": {
        "id": "zP_NtgJPKmQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define MyGD"
      ],
      "metadata": {
        "id": "eN5F-VOMPcW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyGD(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr=0.001):\n",
        "        defaults = dict(lr=lr)\n",
        "        super(MyGD, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                p.data.add_(-group['lr'], grad)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "dHZOyDnbKmit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Optimization Problem <h1>\n",
        "$ \\min f(x_1, x_2) = \\frac{x_2^2}{x_1^2}$ <h1>\n",
        "Subject to $ x_2>0 $"
      ],
      "metadata": {
        "id": "GcvYFbdhQEDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the objective function"
      ],
      "metadata": {
        "id": "rI27zWDFR0VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(x1, x2):\n",
        "    return x1**2 / x2\n",
        "\n",
        "def grad_objective(x1, x2):\n",
        "    grad_x1 = 2 * x1 / x2\n",
        "    grad_x2 = -1 * x1**2 / x2**2\n",
        "    return torch.tensor([grad_x1, grad_x2])\n",
        "\n",
        "# Initial values\n",
        "x1 = torch.tensor([1.0], requires_grad=True)\n",
        "z = torch.tensor([0.0], requires_grad=True)"
      ],
      "metadata": {
        "id": "83awsZQjPWqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use MyGD"
      ],
      "metadata": {
        "id": "rVa2vxFhR9QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = MyGD([x1, z], lr=0.01)"
      ],
      "metadata": {
        "id": "4-w9MoJXRq96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GD Loop"
      ],
      "metadata": {
        "id": "SJjxuMlxSOWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    x2 = torch.exp(z)\n",
        "    loss = objective(x1, x2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print or log the iteration information\n",
        "    print(f'Iteration {i + 1}/{1000}, x1: {x1.item()}, x2: {x2.item()}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa3Km9uwSCpR",
        "outputId": "45b428ea-ffe4-495c-fc59-58c043e2ccf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-a46be5571cb1>:20: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  p.data.add_(-group['lr'], grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/1000, x1: 0.9800000190734863, x2: 1.0, Loss: 1.0\n",
            "Iteration 2/1000, x1: 0.9605950713157654, x2: 1.0100501775741577, Loss: 0.950843870639801\n",
            "Iteration 3/1000, x1: 0.9417543411254883, x2: 1.0196999311447144, Loss: 0.9049161076545715\n",
            "Iteration 4/1000, x1: 0.9234495162963867, x2: 1.0289692878723145, Loss: 0.8619317412376404\n",
            "Iteration 5/1000, x1: 0.9056545495986938, x2: 1.0378766059875488, Loss: 0.8216381669044495\n",
            "Iteration 6/1000, x1: 0.8883453011512756, x2: 1.046439290046692, Loss: 0.783810555934906\n",
            "Iteration 7/1000, x1: 0.8714994192123413, x2: 1.054673671722412, Loss: 0.7482479214668274\n",
            "Iteration 8/1000, x1: 0.855096161365509, x2: 1.0625948905944824, Loss: 0.7147702574729919\n",
            "Iteration 9/1000, x1: 0.8391162753105164, x2: 1.0702171325683594, Loss: 0.6832159757614136\n",
            "Iteration 10/1000, x1: 0.8235418200492859, x2: 1.0775541067123413, Loss: 0.6534392237663269\n",
            "Iteration 11/1000, x1: 0.808355987071991, x2: 1.084618330001831, Loss: 0.6253085136413574\n",
            "Iteration 12/1000, x1: 0.7935431003570557, x2: 1.0914217233657837, Loss: 0.5987047553062439\n",
            "Iteration 13/1000, x1: 0.7790884375572205, x2: 1.097975730895996, Loss: 0.5735196471214294\n",
            "Iteration 14/1000, x1: 0.7649782299995422, x2: 1.1042909622192383, Loss: 0.5496547222137451\n",
            "Iteration 15/1000, x1: 0.7511995434761047, x2: 1.1103774309158325, Loss: 0.5270205140113831\n",
            "Iteration 16/1000, x1: 0.737740159034729, x2: 1.1162447929382324, Loss: 0.5055349469184875\n",
            "Iteration 17/1000, x1: 0.7245885729789734, x2: 1.1219021081924438, Loss: 0.48512303829193115\n",
            "Iteration 18/1000, x1: 0.7117339372634888, x2: 1.1273579597473145, Loss: 0.4657159447669983\n",
            "Iteration 19/1000, x1: 0.6991659998893738, x2: 1.1326204538345337, Loss: 0.447250634431839\n",
            "Iteration 20/1000, x1: 0.6868751049041748, x2: 1.137697458267212, Loss: 0.4296687841415405\n",
            "Iteration 21/1000, x1: 0.6748520731925964, x2: 1.1425963640213013, Loss: 0.41291695833206177\n",
            "Iteration 22/1000, x1: 0.6630881428718567, x2: 1.1473240852355957, Loss: 0.39694565534591675\n",
            "Iteration 23/1000, x1: 0.6515750885009766, x2: 1.1518874168395996, Loss: 0.3817090690135956\n",
            "Iteration 24/1000, x1: 0.6403050422668457, x2: 1.1562926769256592, Loss: 0.3671649098396301\n",
            "Iteration 25/1000, x1: 0.6292704939842224, x2: 1.1605459451675415, Loss: 0.353273868560791\n",
            "Iteration 26/1000, x1: 0.6184643507003784, x2: 1.1646530628204346, Loss: 0.33999940752983093\n",
            "Iteration 27/1000, x1: 0.6078798174858093, x2: 1.1686196327209473, Loss: 0.32730764150619507\n",
            "Iteration 28/1000, x1: 0.5975104570388794, x2: 1.1724509000778198, Loss: 0.31516703963279724\n",
            "Iteration 29/1000, x1: 0.5873500108718872, x2: 1.1761518716812134, Loss: 0.3035481572151184\n",
            "Iteration 30/1000, x1: 0.5773926377296448, x2: 1.179727554321289, Loss: 0.2924234867095947\n",
            "Iteration 31/1000, x1: 0.5676326155662537, x2: 1.1831823587417603, Loss: 0.28176742792129517\n",
            "Iteration 32/1000, x1: 0.5580645799636841, x2: 1.1865209341049194, Loss: 0.27155593037605286\n",
            "Iteration 33/1000, x1: 0.5486833453178406, x2: 1.1897473335266113, Loss: 0.26176658272743225\n",
            "Iteration 34/1000, x1: 0.539483904838562, x2: 1.1928657293319702, Loss: 0.25237828493118286\n",
            "Iteration 35/1000, x1: 0.5304615497589111, x2: 1.1958800554275513, Loss: 0.24337130784988403\n",
            "Iteration 36/1000, x1: 0.5216116309165955, x2: 1.1987941265106201, Loss: 0.23472708463668823\n",
            "Iteration 37/1000, x1: 0.5129297375679016, x2: 1.2016112804412842, Loss: 0.22642821073532104\n",
            "Iteration 38/1000, x1: 0.5044116973876953, x2: 1.2043352127075195, Loss: 0.21845822036266327\n",
            "Iteration 39/1000, x1: 0.4960533678531647, x2: 1.2069690227508545, Loss: 0.21080173552036285\n",
            "Iteration 40/1000, x1: 0.4878508448600769, x2: 1.2095160484313965, Loss: 0.20344412326812744\n",
            "Iteration 41/1000, x1: 0.47980037331581116, x2: 1.2119791507720947, Loss: 0.19637173414230347\n",
            "Iteration 42/1000, x1: 0.47189828753471375, x2: 1.214361548423767, Loss: 0.1895715445280075\n",
            "Iteration 43/1000, x1: 0.46414104104042053, x2: 1.2166657447814941, Loss: 0.183031365275383\n",
            "Iteration 44/1000, x1: 0.4565252661705017, x2: 1.2188947200775146, Loss: 0.17673955857753754\n",
            "Iteration 45/1000, x1: 0.44904768466949463, x2: 1.2210508584976196, Loss: 0.17068520188331604\n",
            "Iteration 46/1000, x1: 0.4417051374912262, x2: 1.2231367826461792, Loss: 0.16485795378684998\n",
            "Iteration 47/1000, x1: 0.4344945251941681, x2: 1.2251548767089844, Loss: 0.1592479646205902\n",
            "Iteration 48/1000, x1: 0.4274129271507263, x2: 1.2271075248718262, Loss: 0.1538459211587906\n",
            "Iteration 49/1000, x1: 0.4204574525356293, x2: 1.228996753692627, Loss: 0.14864304661750793\n",
            "Iteration 50/1000, x1: 0.4136253297328949, x2: 1.2308249473571777, Loss: 0.14363087713718414\n",
            "Iteration 51/1000, x1: 0.4069138765335083, x2: 1.2325941324234009, Loss: 0.13880150020122528\n",
            "Iteration 52/1000, x1: 0.40032047033309937, x2: 1.2343060970306396, Loss: 0.13414736092090607\n",
            "Iteration 53/1000, x1: 0.3938426077365875, x2: 1.235962986946106, Loss: 0.12966123223304749\n",
            "Iteration 54/1000, x1: 0.3874778151512146, x2: 1.237566590309143, Loss: 0.12533628940582275\n",
            "Iteration 55/1000, x1: 0.38122373819351196, x2: 1.2391186952590942, Loss: 0.12116600573062897\n",
            "Iteration 56/1000, x1: 0.3750780522823334, x2: 1.2406210899353027, Loss: 0.11714417487382889\n",
            "Iteration 57/1000, x1: 0.36903852224349976, x2: 1.2420752048492432, Loss: 0.11326491832733154\n",
            "Iteration 58/1000, x1: 0.3631029725074768, x2: 1.2434828281402588, Loss: 0.10952256619930267\n",
            "Iteration 59/1000, x1: 0.3572692573070526, x2: 1.2448455095291138, Loss: 0.1059117540717125\n",
            "Iteration 60/1000, x1: 0.3515353500843048, x2: 1.2461645603179932, Loss: 0.10242734104394913\n",
            "Iteration 61/1000, x1: 0.3458992540836334, x2: 1.2474416494369507, Loss: 0.0990644320845604\n",
            "Iteration 62/1000, x1: 0.34035900235176086, x2: 1.2486780881881714, Loss: 0.09581837058067322\n",
            "Iteration 63/1000, x1: 0.3349127173423767, x2: 1.2498750686645508, Loss: 0.09268466383218765\n",
            "Iteration 64/1000, x1: 0.3295585513114929, x2: 1.251034140586853, Loss: 0.08965905010700226\n",
            "Iteration 65/1000, x1: 0.32429468631744385, x2: 1.2521562576293945, Loss: 0.08673745393753052\n",
            "Iteration 66/1000, x1: 0.319119393825531, x2: 1.25324285030365, Loss: 0.08391593396663666\n",
            "Iteration 67/1000, x1: 0.3140309751033783, x2: 1.2542948722839355, Loss: 0.08119078725576401\n",
            "Iteration 68/1000, x1: 0.309027761220932, x2: 1.255313754081726, Loss: 0.07855840772390366\n",
            "Iteration 69/1000, x1: 0.3041081130504608, x2: 1.2563002109527588, Loss: 0.0760153979063034\n",
            "Iteration 70/1000, x1: 0.2992704510688782, x2: 1.2572555541992188, Loss: 0.07355843484401703\n",
            "Iteration 71/1000, x1: 0.2945132553577423, x2: 1.2581807374954224, Loss: 0.07118436694145203\n",
            "Iteration 72/1000, x1: 0.28983500599861145, x2: 1.259076714515686, Loss: 0.06889020651578903\n",
            "Iteration 73/1000, x1: 0.2852342426776886, x2: 1.2599443197250366, Loss: 0.06667304784059525\n",
            "Iteration 74/1000, x1: 0.28070953488349915, x2: 1.2607847452163696, Loss: 0.06453010439872742\n",
            "Iteration 75/1000, x1: 0.27625948190689087, x2: 1.2615985870361328, Loss: 0.06245872378349304\n",
            "Iteration 76/1000, x1: 0.27188271284103394, x2: 1.2623867988586426, Loss: 0.060456350445747375\n",
            "Iteration 77/1000, x1: 0.2675778865814209, x2: 1.2631502151489258, Loss: 0.05852052569389343\n",
            "Iteration 78/1000, x1: 0.2633436918258667, x2: 1.2638895511627197, Loss: 0.05664888024330139\n",
            "Iteration 79/1000, x1: 0.25917884707450867, x2: 1.2646057605743408, Loss: 0.05483914539217949\n",
            "Iteration 80/1000, x1: 0.2550821304321289, x2: 1.2652994394302368, Loss: 0.05308915302157402\n",
            "Iteration 81/1000, x1: 0.2510523200035095, x2: 1.2659714221954346, Loss: 0.05139681324362755\n",
            "Iteration 82/1000, x1: 0.24708819389343262, x2: 1.2666221857070923, Loss: 0.0497601181268692\n",
            "Iteration 83/1000, x1: 0.24318860471248627, x2: 1.2672526836395264, Loss: 0.04817711189389229\n",
            "Iteration 84/1000, x1: 0.23935240507125854, x2: 1.2678632736206055, Loss: 0.046645957976579666\n",
            "Iteration 85/1000, x1: 0.2355784773826599, x2: 1.268454909324646, Loss: 0.04516484960913658\n",
            "Iteration 86/1000, x1: 0.23186573386192322, x2: 1.2690279483795166, Loss: 0.04373206943273544\n",
            "Iteration 87/1000, x1: 0.2282131016254425, x2: 1.269582986831665, Loss: 0.042345963418483734\n",
            "Iteration 88/1000, x1: 0.2246195375919342, x2: 1.2701207399368286, Loss: 0.04100493714213371\n",
            "Iteration 89/1000, x1: 0.22108401358127594, x2: 1.2706416845321655, Loss: 0.03970744460821152\n",
            "Iteration 90/1000, x1: 0.21760551631450653, x2: 1.271146297454834, Loss: 0.038452018052339554\n",
            "Iteration 91/1000, x1: 0.21418306231498718, x2: 1.2716351747512817, Loss: 0.037237223237752914\n",
            "Iteration 92/1000, x1: 0.2108156979084015, x2: 1.272108793258667, Loss: 0.03606168180704117\n",
            "Iteration 93/1000, x1: 0.20750246942043304, x2: 1.272567629814148, Loss: 0.03492408245801926\n",
            "Iteration 94/1000, x1: 0.20424245297908783, x2: 1.2730121612548828, Loss: 0.03382314369082451\n",
            "Iteration 95/1000, x1: 0.20103472471237183, x2: 1.2734427452087402, Loss: 0.03275763988494873\n",
            "Iteration 96/1000, x1: 0.1978784203529358, x2: 1.273859977722168, Loss: 0.031726375222206116\n",
            "Iteration 97/1000, x1: 0.1947726458311081, x2: 1.2742642164230347, Loss: 0.03072821907699108\n",
            "Iteration 98/1000, x1: 0.19171656668186188, x2: 1.274655818939209, Loss: 0.029762059450149536\n",
            "Iteration 99/1000, x1: 0.1887093335390091, x2: 1.2750352621078491, Loss: 0.028826843947172165\n",
            "Iteration 100/1000, x1: 0.18575012683868408, x2: 1.2754027843475342, Loss: 0.027921542525291443\n",
            "Iteration 101/1000, x1: 0.18283812701702118, x2: 1.275758981704712, Loss: 0.02704516239464283\n",
            "Iteration 102/1000, x1: 0.1799725592136383, x2: 1.2761040925979614, Loss: 0.02619674988090992\n",
            "Iteration 103/1000, x1: 0.17715264856815338, x2: 1.2764383554458618, Loss: 0.02537539042532444\n",
            "Iteration 104/1000, x1: 0.17437762022018433, x2: 1.2767623662948608, Loss: 0.02458018809556961\n",
            "Iteration 105/1000, x1: 0.17164672911167145, x2: 1.277076244354248, Loss: 0.023810287937521935\n",
            "Iteration 106/1000, x1: 0.16895924508571625, x2: 1.277380347251892, Loss: 0.023064861074090004\n",
            "Iteration 107/1000, x1: 0.16631445288658142, x2: 1.2776750326156616, Loss: 0.0223431047052145\n",
            "Iteration 108/1000, x1: 0.16371163725852966, x2: 1.2779604196548462, Loss: 0.02164425142109394\n",
            "Iteration 109/1000, x1: 0.16115011274814606, x2: 1.2782371044158936, Loss: 0.020967550575733185\n",
            "Iteration 110/1000, x1: 0.15862919390201569, x2: 1.2785052061080933, Loss: 0.02031228132545948\n",
            "Iteration 111/1000, x1: 0.15614822506904602, x2: 1.2787648439407349, Loss: 0.01967775449156761\n",
            "Iteration 112/1000, x1: 0.15370653569698334, x2: 1.2790164947509766, Loss: 0.019063295796513557\n",
            "Iteration 113/1000, x1: 0.1513034850358963, x2: 1.2792603969573975, Loss: 0.018468249589204788\n",
            "Iteration 114/1000, x1: 0.14893843233585358, x2: 1.279496669769287, Loss: 0.01789199188351631\n",
            "Iteration 115/1000, x1: 0.14661076664924622, x2: 1.2797255516052246, Loss: 0.017333917319774628\n",
            "Iteration 116/1000, x1: 0.14431987702846527, x2: 1.2799474000930786, Loss: 0.01679343730211258\n",
            "Iteration 117/1000, x1: 0.142065167427063, x2: 1.2801624536514282, Loss: 0.01626998744904995\n",
            "Iteration 118/1000, x1: 0.1398460417985916, x2: 1.2803707122802734, Loss: 0.015763022005558014\n",
            "Iteration 119/1000, x1: 0.1376619189977646, x2: 1.280572533607483, Loss: 0.015272009186446667\n",
            "Iteration 120/1000, x1: 0.13551224768161774, x2: 1.2807681560516357, Loss: 0.01479643490165472\n",
            "Iteration 121/1000, x1: 0.1333964467048645, x2: 1.2809576988220215, Loss: 0.01433581206947565\n",
            "Iteration 122/1000, x1: 0.1313139796257019, x2: 1.2811412811279297, Loss: 0.013889657333493233\n",
            "Iteration 123/1000, x1: 0.12926431000232697, x2: 1.281319260597229, Loss: 0.013457505963742733\n",
            "Iteration 124/1000, x1: 0.1272469013929367, x2: 1.281491756439209, Loss: 0.01303891558200121\n",
            "Iteration 125/1000, x1: 0.12526124715805054, x2: 1.2816587686538696, Loss: 0.012633451260626316\n",
            "Iteration 126/1000, x1: 0.12330681830644608, x2: 1.2818207740783691, Loss: 0.012240697629749775\n",
            "Iteration 127/1000, x1: 0.12138312309980392, x2: 1.281977653503418, Loss: 0.011860246770083904\n",
            "Iteration 128/1000, x1: 0.11948966234922409, x2: 1.2821297645568848, Loss: 0.011491709388792515\n",
            "Iteration 129/1000, x1: 0.11762595176696777, x2: 1.2822771072387695, Loss: 0.011134706437587738\n",
            "Iteration 130/1000, x1: 0.11579151451587677, x2: 1.2824198007583618, Loss: 0.010788872838020325\n",
            "Iteration 131/1000, x1: 0.11398588120937347, x2: 1.2825582027435303, Loss: 0.010453852824866772\n",
            "Iteration 132/1000, x1: 0.11220858991146088, x2: 1.282692313194275, Loss: 0.010129304602742195\n",
            "Iteration 133/1000, x1: 0.11045918613672256, x2: 1.2828222513198853, Loss: 0.009814896620810032\n",
            "Iteration 134/1000, x1: 0.10873723030090332, x2: 1.2829481363296509, Loss: 0.00951030757278204\n",
            "Iteration 135/1000, x1: 0.10704227536916733, x2: 1.2830702066421509, Loss: 0.00921522919088602\n",
            "Iteration 136/1000, x1: 0.10537389665842056, x2: 1.2831883430480957, Loss: 0.008929358795285225\n",
            "Iteration 137/1000, x1: 0.103731669485569, x2: 1.2833030223846436, Loss: 0.008652405813336372\n",
            "Iteration 138/1000, x1: 0.10211517661809921, x2: 1.2834140062332153, Loss: 0.008384089916944504\n",
            "Iteration 139/1000, x1: 0.10052400827407837, x2: 1.2835216522216797, Loss: 0.008124140091240406\n",
            "Iteration 140/1000, x1: 0.09895775467157364, x2: 1.283625841140747, Loss: 0.007872290909290314\n",
            "Iteration 141/1000, x1: 0.09741602838039398, x2: 1.2837269306182861, Loss: 0.007628286723047495\n",
            "Iteration 142/1000, x1: 0.09589843451976776, x2: 1.2838249206542969, Loss: 0.007391882129013538\n",
            "Iteration 143/1000, x1: 0.09440459311008453, x2: 1.2839198112487793, Loss: 0.007162837777286768\n",
            "Iteration 144/1000, x1: 0.09293413162231445, x2: 1.284011721611023, Loss: 0.006940923631191254\n",
            "Iteration 145/1000, x1: 0.09148667007684708, x2: 1.284100890159607, Loss: 0.006725914776325226\n",
            "Iteration 146/1000, x1: 0.09006185084581375, x2: 1.2841871976852417, Loss: 0.006517594214528799\n",
            "Iteration 147/1000, x1: 0.08865931630134583, x2: 1.284271001815796, Loss: 0.0063157519325613976\n",
            "Iteration 148/1000, x1: 0.08727870881557465, x2: 1.2843520641326904, Loss: 0.006120186764746904\n",
            "Iteration 149/1000, x1: 0.08591968566179276, x2: 1.284430742263794, Loss: 0.005930699408054352\n",
            "Iteration 150/1000, x1: 0.0845819041132927, x2: 1.284506916999817, Loss: 0.0057471017353236675\n",
            "Iteration 151/1000, x1: 0.083265021443367, x2: 1.2845807075500488, Loss: 0.005569209344685078\n",
            "Iteration 152/1000, x1: 0.08196871727705002, x2: 1.2846522331237793, Loss: 0.0053968410938978195\n",
            "Iteration 153/1000, x1: 0.08069266378879547, x2: 1.2847216129302979, Loss: 0.005229826085269451\n",
            "Iteration 154/1000, x1: 0.0794365406036377, x2: 1.284788727760315, Loss: 0.005067997612059116\n",
            "Iteration 155/1000, x1: 0.07820003479719162, x2: 1.2848539352416992, Loss: 0.004911191761493683\n",
            "Iteration 156/1000, x1: 0.07698283344507217, x2: 1.2849169969558716, Loss: 0.004759253468364477\n",
            "Iteration 157/1000, x1: 0.07578463852405548, x2: 1.2849781513214111, Loss: 0.004612029064446688\n",
            "Iteration 158/1000, x1: 0.07460514456033707, x2: 1.2850373983383179, Loss: 0.004469372797757387\n",
            "Iteration 159/1000, x1: 0.07344406098127365, x2: 1.2850948572158813, Loss: 0.004331141244620085\n",
            "Iteration 160/1000, x1: 0.07230109721422195, x2: 1.2851505279541016, Loss: 0.004197197034955025\n",
            "Iteration 161/1000, x1: 0.0711759701371193, x2: 1.285204529762268, Loss: 0.004067406058311462\n",
            "Iteration 162/1000, x1: 0.07006839662790298, x2: 1.2852567434310913, Loss: 0.003941639326512814\n",
            "Iteration 163/1000, x1: 0.06897810101509094, x2: 1.2853074073791504, Loss: 0.003819771111011505\n",
            "Iteration 164/1000, x1: 0.06790480762720108, x2: 1.2853565216064453, Loss: 0.0037016798742115498\n",
            "Iteration 165/1000, x1: 0.0668482556939125, x2: 1.285404086112976, Loss: 0.003587247570976615\n",
            "Iteration 166/1000, x1: 0.06580817699432373, x2: 1.2854502201080322, Loss: 0.003476361045613885\n",
            "Iteration 167/1000, x1: 0.06478431820869446, x2: 1.2854949235916138, Loss: 0.0033689094707369804\n",
            "Iteration 168/1000, x1: 0.0637764260172844, x2: 1.2855381965637207, Loss: 0.0032647866755723953\n",
            "Iteration 169/1000, x1: 0.06278424710035324, x2: 1.2855801582336426, Loss: 0.00316388881765306\n",
            "Iteration 170/1000, x1: 0.061807531863451004, x2: 1.2856208086013794, Loss: 0.0030661155469715595\n",
            "Iteration 171/1000, x1: 0.06084604188799858, x2: 1.2856602668762207, Loss: 0.0029713688418269157\n",
            "Iteration 172/1000, x1: 0.05989953503012657, x2: 1.285698413848877, Loss: 0.0028795560356229544\n",
            "Iteration 173/1000, x1: 0.05896778032183647, x2: 1.2857354879379272, Loss: 0.0027905849274247885\n",
            "Iteration 174/1000, x1: 0.05805054306983948, x2: 1.285771369934082, Loss: 0.002704367972910404\n",
            "Iteration 175/1000, x1: 0.05714759975671768, x2: 1.2858060598373413, Loss: 0.002620819490402937\n",
            "Iteration 176/1000, x1: 0.05625872313976288, x2: 1.2858397960662842, Loss: 0.0025398561265319586\n",
            "Iteration 177/1000, x1: 0.05538369342684746, x2: 1.285872459411621, Loss: 0.002461398020386696\n",
            "Iteration 178/1000, x1: 0.05452229827642441, x2: 1.285904049873352, Loss: 0.0023853674065321684\n",
            "Iteration 179/1000, x1: 0.05367431789636612, x2: 1.2859348058700562, Loss: 0.0023116888478398323\n",
            "Iteration 180/1000, x1: 0.05283954739570618, x2: 1.2859644889831543, Loss: 0.0022402892354875803\n",
            "Iteration 181/1000, x1: 0.052017778158187866, x2: 1.2859933376312256, Loss: 0.002171098254621029\n",
            "Iteration 182/1000, x1: 0.05120880529284477, x2: 1.2860212326049805, Loss: 0.0021040469873696566\n",
            "Iteration 183/1000, x1: 0.05041243135929108, x2: 1.2860482931137085, Loss: 0.0020390693098306656\n",
            "Iteration 184/1000, x1: 0.04962845891714096, x2: 1.2860745191574097, Loss: 0.001976101193577051\n",
            "Iteration 185/1000, x1: 0.048856690526008606, x2: 1.286099910736084, Loss: 0.001915079657919705\n",
            "Iteration 186/1000, x1: 0.04809693992137909, x2: 1.286124587059021, Loss: 0.0018559448653832078\n",
            "Iteration 187/1000, x1: 0.04734901711344719, x2: 1.2861484289169312, Loss: 0.001798638142645359\n",
            "Iteration 188/1000, x1: 0.04661273956298828, x2: 1.286171555519104, Loss: 0.0017431030282750726\n",
            "Iteration 189/1000, x1: 0.04588792473077774, x2: 1.2861939668655396, Loss: 0.0016892843414098024\n",
            "Iteration 190/1000, x1: 0.04517439007759094, x2: 1.2862157821655273, Loss: 0.0016371294623240829\n",
            "Iteration 191/1000, x1: 0.04447196424007416, x2: 1.2862367630004883, Loss: 0.0015865861205384135\n",
            "Iteration 192/1000, x1: 0.04378046840429306, x2: 1.2862571477890015, Loss: 0.0015376051887869835\n",
            "Iteration 193/1000, x1: 0.04309973865747452, x2: 1.286276936531067, Loss: 0.00149013742338866\n",
            "Iteration 194/1000, x1: 0.0424295999109745, x2: 1.2862961292266846, Loss: 0.0014441367238759995\n",
            "Iteration 195/1000, x1: 0.04176989197731018, x2: 1.2863147258758545, Loss: 0.0013995571061968803\n",
            "Iteration 196/1000, x1: 0.04112045094370842, x2: 1.2863327264785767, Loss: 0.0013563550310209394\n",
            "Iteration 197/1000, x1: 0.040481116622686386, x2: 1.286350131034851, Loss: 0.001314487773925066\n",
            "Iteration 198/1000, x1: 0.039851728826761246, x2: 1.2863670587539673, Loss: 0.0012739138910546899\n",
            "Iteration 199/1000, x1: 0.03923213481903076, x2: 1.2863833904266357, Loss: 0.0012345933355391026\n",
            "Iteration 200/1000, x1: 0.0386221818625927, x2: 1.2863993644714355, Loss: 0.0011964872246608138\n",
            "Iteration 201/1000, x1: 0.038021720945835114, x2: 1.2864147424697876, Loss: 0.001159558305516839\n",
            "Iteration 202/1000, x1: 0.037430599331855774, x2: 1.2864296436309814, Loss: 0.0011237701401114464\n",
            "Iteration 203/1000, x1: 0.03684867545962334, x2: 1.286444067955017, Loss: 0.0010890872217714787\n",
            "Iteration 204/1000, x1: 0.03627580404281616, x2: 1.2864580154418945, Loss: 0.0010554754408076406\n",
            "Iteration 205/1000, x1: 0.03571184724569321, x2: 1.2864716053009033, Loss: 0.0010229017352685332\n",
            "Iteration 206/1000, x1: 0.03515666350722313, x2: 1.2864848375320435, Loss: 0.0009913338581100106\n",
            "Iteration 207/1000, x1: 0.034610114991664886, x2: 1.2864975929260254, Loss: 0.0009607410174794495\n",
            "Iteration 208/1000, x1: 0.034072067588567734, x2: 1.2865098714828491, Loss: 0.0009310928289778531\n",
            "Iteration 209/1000, x1: 0.033542390912771225, x2: 1.2865219116210938, Loss: 0.00090235989773646\n",
            "Iteration 210/1000, x1: 0.033020950853824615, x2: 1.2865334749221802, Loss: 0.0008745144004933536\n",
            "Iteration 211/1000, x1: 0.032507624477148056, x2: 1.286544680595398, Loss: 0.0008475283975712955\n",
            "Iteration 212/1000, x1: 0.0320022813975811, x2: 1.2865556478500366, Loss: 0.0008213757537305355\n",
            "Iteration 213/1000, x1: 0.0315047986805439, x2: 1.286566138267517, Loss: 0.0007960305665619671\n",
            "Iteration 214/1000, x1: 0.031015051528811455, x2: 1.2865763902664185, Loss: 0.0007714678649790585\n",
            "Iteration 215/1000, x1: 0.030532922595739365, x2: 1.2865864038467407, Loss: 0.0007476632599718869\n",
            "Iteration 216/1000, x1: 0.03005829080939293, x2: 1.2865959405899048, Loss: 0.0007245937595143914\n",
            "Iteration 217/1000, x1: 0.029591040685772896, x2: 1.2866052389144897, Loss: 0.0007022362551651895\n",
            "Iteration 218/1000, x1: 0.029131056740880013, x2: 1.2866142988204956, Loss: 0.0006805689190514386\n",
            "Iteration 219/1000, x1: 0.028678227216005325, x2: 1.2866231203079224, Loss: 0.0006595703307539225\n",
            "Iteration 220/1000, x1: 0.02823244035243988, x2: 1.2866315841674805, Loss: 0.0006392200593836606\n",
            "Iteration 221/1000, x1: 0.027793584391474724, x2: 1.2866398096084595, Loss: 0.0006194979068823159\n",
            "Iteration 222/1000, x1: 0.02736155316233635, x2: 1.2866476774215698, Loss: 0.0006003845483064651\n",
            "Iteration 223/1000, x1: 0.02693624049425125, x2: 1.2866554260253906, Loss: 0.0005818610079586506\n",
            "Iteration 224/1000, x1: 0.026517542079091072, x2: 1.2866629362106323, Loss: 0.0005639091832563281\n",
            "Iteration 225/1000, x1: 0.026105353608727455, x2: 1.286670207977295, Loss: 0.0005465114954859018\n",
            "Iteration 226/1000, x1: 0.025699574500322342, x2: 1.2866772413253784, Loss: 0.0005296506569720805\n",
            "Iteration 227/1000, x1: 0.025300104171037674, x2: 1.2866840362548828, Loss: 0.0005133102531544864\n",
            "Iteration 228/1000, x1: 0.02490684576332569, x2: 1.286690592765808, Loss: 0.0004974741023033857\n",
            "Iteration 229/1000, x1: 0.024519702419638634, x2: 1.2866970300674438, Loss: 0.0004821266629733145\n",
            "Iteration 230/1000, x1: 0.02413857728242874, x2: 1.2867032289505005, Loss: 0.00046725288848392665\n",
            "Iteration 231/1000, x1: 0.023763379082083702, x2: 1.286709189414978, Loss: 0.0004528380814008415\n",
            "Iteration 232/1000, x1: 0.023394014686346054, x2: 1.286715030670166, Loss: 0.000438868097262457\n",
            "Iteration 233/1000, x1: 0.023030392825603485, x2: 1.2867207527160645, Loss: 0.0004253291990607977\n",
            "Iteration 234/1000, x1: 0.022672424092888832, x2: 1.2867262363433838, Loss: 0.0004122080863453448\n",
            "Iteration 235/1000, x1: 0.02232002094388008, x2: 1.286731481552124, Loss: 0.00039949192432686687\n",
            "Iteration 236/1000, x1: 0.02197309583425522, x2: 1.2867366075515747, Loss: 0.0003871680819429457\n",
            "Iteration 237/1000, x1: 0.02163156494498253, x2: 1.2867416143417358, Loss: 0.0003752244811039418\n",
            "Iteration 238/1000, x1: 0.021295344457030296, x2: 1.2867463827133179, Loss: 0.00036364945117384195\n",
            "Iteration 239/1000, x1: 0.020964350551366806, x2: 1.2867511510849, Loss: 0.0003524315543472767\n",
            "Iteration 240/1000, x1: 0.02063850313425064, x2: 1.2867556810379028, Loss: 0.00034155978937633336\n",
            "Iteration 241/1000, x1: 0.020317720249295235, x2: 1.2867600917816162, Loss: 0.00033102347515523434\n",
            "Iteration 242/1000, x1: 0.02000192552804947, x2: 1.2867642641067505, Loss: 0.00032081225072033703\n",
            "Iteration 243/1000, x1: 0.019691038876771927, x2: 1.2867684364318848, Loss: 0.00031091610435396433\n",
            "Iteration 244/1000, x1: 0.01938498578965664, x2: 1.2867724895477295, Loss: 0.0003013252280652523\n",
            "Iteration 245/1000, x1: 0.019083689898252487, x2: 1.2867763042449951, Loss: 0.0002920303086284548\n",
            "Iteration 246/1000, x1: 0.01878707855939865, x2: 1.2867801189422607, Loss: 0.00028302212012931705\n",
            "Iteration 247/1000, x1: 0.01849507726728916, x2: 1.2867836952209473, Loss: 0.0002742918732110411\n",
            "Iteration 248/1000, x1: 0.018207615241408348, x2: 1.2867872714996338, Loss: 0.00026583095313981175\n",
            "Iteration 249/1000, x1: 0.01792462170124054, x2: 1.2867906093597412, Loss: 0.00025763106532394886\n",
            "Iteration 250/1000, x1: 0.017646027728915215, x2: 1.2867939472198486, Loss: 0.0002496841480024159\n",
            "Iteration 251/1000, x1: 0.01737176440656185, x2: 1.2867971658706665, Loss: 0.00024198241590056568\n",
            "Iteration 252/1000, x1: 0.017101764678955078, x2: 1.2868002653121948, Loss: 0.00023451828747056425\n",
            "Iteration 253/1000, x1: 0.016835961490869522, x2: 1.2868033647537231, Loss: 0.00022728442854713649\n",
            "Iteration 254/1000, x1: 0.01657429151237011, x2: 1.2868062257766724, Loss: 0.00022027372324373573\n",
            "Iteration 255/1000, x1: 0.016316687688231468, x2: 1.2868090867996216, Loss: 0.00021347931760828942\n",
            "Iteration 256/1000, x1: 0.016063088551163673, x2: 1.2868118286132812, Loss: 0.00020689450320787728\n",
            "Iteration 257/1000, x1: 0.0158134326338768, x2: 1.2868144512176514, Loss: 0.00020051283354405314\n",
            "Iteration 258/1000, x1: 0.015567656606435776, x2: 1.2868170738220215, Loss: 0.0001943280512932688\n",
            "Iteration 259/1000, x1: 0.015325700864195824, x2: 1.286819577217102, Loss: 0.00018833404465112835\n",
            "Iteration 260/1000, x1: 0.015087506733834743, x2: 1.286821961402893, Loss: 0.00018252494919579476\n",
            "Iteration 261/1000, x1: 0.01485301461070776, x2: 1.286824345588684, Loss: 0.00017689504602458328\n",
            "Iteration 262/1000, x1: 0.014622167684137821, x2: 1.286826491355896, Loss: 0.00017143883451353759\n",
            "Iteration 263/1000, x1: 0.014394909143447876, x2: 1.2868287563323975, Loss: 0.00016615091590210795\n",
            "Iteration 264/1000, x1: 0.014171182177960873, x2: 1.2868309020996094, Loss: 0.00016102613881230354\n",
            "Iteration 265/1000, x1: 0.013950932770967484, x2: 1.2868330478668213, Loss: 0.00015605941007379442\n",
            "Iteration 266/1000, x1: 0.013734106905758381, x2: 1.286834955215454, Loss: 0.00015124591300264\n",
            "Iteration 267/1000, x1: 0.013520651496946812, x2: 1.2868369817733765, Loss: 0.0001465808745706454\n",
            "Iteration 268/1000, x1: 0.013310514390468597, x2: 1.2868387699127197, Loss: 0.00014205976913217455\n",
            "Iteration 269/1000, x1: 0.01310364343225956, x2: 1.2868406772613525, Loss: 0.00013767810014542192\n",
            "Iteration 270/1000, x1: 0.012899987399578094, x2: 1.2868424654006958, Loss: 0.00013343161845114082\n",
            "Iteration 271/1000, x1: 0.012699496932327747, x2: 1.2868441343307495, Loss: 0.00012931610399391502\n",
            "Iteration 272/1000, x1: 0.012502122670412064, x2: 1.2868458032608032, Loss: 0.0001253275404451415\n",
            "Iteration 273/1000, x1: 0.012307816185057163, x2: 1.286847472190857, Loss: 0.00012146199878770858\n",
            "Iteration 274/1000, x1: 0.012116529978811741, x2: 1.286849021911621, Loss: 0.00011771570279961452\n",
            "Iteration 275/1000, x1: 0.011928217485547066, x2: 1.2868504524230957, Loss: 0.00011408497084630653\n",
            "Iteration 276/1000, x1: 0.011742831207811832, x2: 1.2868518829345703, Loss: 0.00011056623770855367\n",
            "Iteration 277/1000, x1: 0.01156032644212246, x2: 1.286853313446045, Loss: 0.00010715601820265874\n",
            "Iteration 278/1000, x1: 0.011380658484995365, x2: 1.2868547439575195, Loss: 0.00010385100176790729\n",
            "Iteration 279/1000, x1: 0.011203783564269543, x2: 1.2868560552597046, Loss: 0.00010064792877528816\n",
            "Iteration 280/1000, x1: 0.01102965697646141, x2: 1.2868573665618896, Loss: 9.754364873515442e-05\n",
            "Iteration 281/1000, x1: 0.010858236812055111, x2: 1.2868586778640747, Loss: 9.453511302126572e-05\n",
            "Iteration 282/1000, x1: 0.010689481161534786, x2: 1.2868598699569702, Loss: 9.161938214674592e-05\n",
            "Iteration 283/1000, x1: 0.010523348115384579, x2: 1.2868610620498657, Loss: 8.879358210833743e-05\n",
            "Iteration 284/1000, x1: 0.01035979762673378, x2: 1.2868622541427612, Loss: 8.605494076618925e-05\n",
            "Iteration 285/1000, x1: 0.010198788717389107, x2: 1.2868633270263672, Loss: 8.340078056789935e-05\n",
            "Iteration 286/1000, x1: 0.010040282271802425, x2: 1.2868643999099731, Loss: 8.082848216872662e-05\n",
            "Iteration 287/1000, x1: 0.009884240105748177, x2: 1.286865472793579, Loss: 7.833551353542134e-05\n",
            "Iteration 288/1000, x1: 0.009730623103678226, x2: 1.2868664264678955, Loss: 7.59194590500556e-05\n",
            "Iteration 289/1000, x1: 0.009579393081367016, x2: 1.286867380142212, Loss: 7.357792492257431e-05\n",
            "Iteration 290/1000, x1: 0.009430513717234135, x2: 1.2868683338165283, Loss: 7.130859012249857e-05\n",
            "Iteration 291/1000, x1: 0.009283948689699173, x2: 1.2868692874908447, Loss: 6.91092645865865e-05\n",
            "Iteration 292/1000, x1: 0.00913966167718172, x2: 1.2868701219558716, Loss: 6.697778007946908e-05\n",
            "Iteration 293/1000, x1: 0.008997617289423943, x2: 1.2868709564208984, Loss: 6.491203384939581e-05\n",
            "Iteration 294/1000, x1: 0.008857780136168003, x2: 1.2868717908859253, Loss: 6.291001045610756e-05\n",
            "Iteration 295/1000, x1: 0.008720116689801216, x2: 1.2868726253509521, Loss: 6.096972356317565e-05\n",
            "Iteration 296/1000, x1: 0.008584592491388321, x2: 1.286873459815979, Loss: 5.908928869757801e-05\n",
            "Iteration 297/1000, x1: 0.008451174944639206, x2: 1.2868741750717163, Loss: 5.7266846852144226e-05\n",
            "Iteration 298/1000, x1: 0.008319830521941185, x2: 1.2868748903274536, Loss: 5.550062269321643e-05\n",
            "Iteration 299/1000, x1: 0.008190527558326721, x2: 1.286875605583191, Loss: 5.3788869990967214e-05\n",
            "Iteration 300/1000, x1: 0.008063234388828278, x2: 1.2868763208389282, Loss: 5.212990799918771e-05\n",
            "Iteration 301/1000, x1: 0.007937919348478317, x2: 1.2868770360946655, Loss: 5.052211054135114e-05\n",
            "Iteration 302/1000, x1: 0.007814552634954453, x2: 1.2868776321411133, Loss: 4.896391328657046e-05\n",
            "Iteration 303/1000, x1: 0.007693103048950434, x2: 1.286878228187561, Loss: 4.7453781007789075e-05\n",
            "Iteration 304/1000, x1: 0.007573540788143873, x2: 1.2868788242340088, Loss: 4.599021849571727e-05\n",
            "Iteration 305/1000, x1: 0.007455836981534958, x2: 1.2868794202804565, Loss: 4.4571792386705056e-05\n",
            "Iteration 306/1000, x1: 0.007339962292462587, x2: 1.2868800163269043, Loss: 4.3197116610826924e-05\n",
            "Iteration 307/1000, x1: 0.007225888781249523, x2: 1.2868804931640625, Loss: 4.186484147794545e-05\n",
            "Iteration 308/1000, x1: 0.0071135880425572395, x2: 1.2868810892105103, Loss: 4.057365367771126e-05\n",
            "Iteration 309/1000, x1: 0.007003032602369785, x2: 1.2868815660476685, Loss: 3.932229446945712e-05\n",
            "Iteration 310/1000, x1: 0.006894195452332497, x2: 1.2868821620941162, Loss: 3.81095233024098e-05\n",
            "Iteration 311/1000, x1: 0.00678704958409071, x2: 1.2868826389312744, Loss: 3.69341614714358e-05\n",
            "Iteration 312/1000, x1: 0.006681568920612335, x2: 1.2868831157684326, Loss: 3.579504482331686e-05\n",
            "Iteration 313/1000, x1: 0.006577727850526571, x2: 1.2868835926055908, Loss: 3.4691063774516806e-05\n",
            "Iteration 314/1000, x1: 0.006475500762462616, x2: 1.2868839502334595, Loss: 3.362113784532994e-05\n",
            "Iteration 315/1000, x1: 0.006374862510710955, x2: 1.2868844270706177, Loss: 3.2584208383923396e-05\n",
            "Iteration 316/1000, x1: 0.00627578841522336, x2: 1.2868847846984863, Loss: 3.1579260394209996e-05\n",
            "Iteration 317/1000, x1: 0.006178253795951605, x2: 1.2868852615356445, Loss: 3.060530798393302e-05\n",
            "Iteration 318/1000, x1: 0.006082234904170036, x2: 1.2868856191635132, Loss: 2.966139254567679e-05\n",
            "Iteration 319/1000, x1: 0.005987708456814289, x2: 1.2868859767913818, Loss: 2.874658821383491e-05\n",
            "Iteration 320/1000, x1: 0.005894651170819998, x2: 1.28688645362854, Loss: 2.785999640764203e-05\n",
            "Iteration 321/1000, x1: 0.005803040228784084, x2: 1.2868868112564087, Loss: 2.700075310713146e-05\n",
            "Iteration 322/1000, x1: 0.005712852813303471, x2: 1.2868871688842773, Loss: 2.6168008844251744e-05\n",
            "Iteration 323/1000, x1: 0.005624067038297653, x2: 1.2868874073028564, Loss: 2.5360948711750098e-05\n",
            "Iteration 324/1000, x1: 0.005536661483347416, x2: 1.286887764930725, Loss: 2.4578779630246572e-05\n",
            "Iteration 325/1000, x1: 0.005450614262372255, x2: 1.2868881225585938, Loss: 2.3820733986212872e-05\n",
            "Iteration 326/1000, x1: 0.0053659044206142426, x2: 1.2868883609771729, Loss: 2.3086071450961754e-05\n",
            "Iteration 327/1000, x1: 0.005282511003315449, x2: 1.2868887186050415, Loss: 2.23740644287318e-05\n",
            "Iteration 328/1000, x1: 0.005200413521379232, x2: 1.2868890762329102, Loss: 2.1684014427592047e-05\n",
            "Iteration 329/1000, x1: 0.005119591951370239, x2: 1.2868893146514893, Loss: 2.1015250240452588e-05\n",
            "Iteration 330/1000, x1: 0.005040026735514402, x2: 1.2868895530700684, Loss: 2.0367111574159935e-05\n",
            "Iteration 331/1000, x1: 0.004961697850376368, x2: 1.2868897914886475, Loss: 1.9738961782422848e-05\n",
            "Iteration 332/1000, x1: 0.004884586203843355, x2: 1.2868901491165161, Loss: 1.9130184227833524e-05\n",
            "Iteration 333/1000, x1: 0.004808673169463873, x2: 1.2868902683258057, Loss: 1.8540184100857005e-05\n",
            "Iteration 334/1000, x1: 0.0047339401207864285, x2: 1.2868905067443848, Loss: 1.7968379324884154e-05\n",
            "Iteration 335/1000, x1: 0.0046603684313595295, x2: 1.2868907451629639, Loss: 1.7414213289157487e-05\n",
            "Iteration 336/1000, x1: 0.004587939940392971, x2: 1.286890983581543, Loss: 1.687713483988773e-05\n",
            "Iteration 337/1000, x1: 0.004516637418419123, x2: 1.286891222000122, Loss: 1.6356621927116066e-05\n",
            "Iteration 338/1000, x1: 0.0044464427046477795, x2: 1.2868914604187012, Loss: 1.5852163414820097e-05\n",
            "Iteration 339/1000, x1: 0.004377339035272598, x2: 1.2868915796279907, Loss: 1.5363262718892656e-05\n",
            "Iteration 340/1000, x1: 0.004309309180825949, x2: 1.2868918180465698, Loss: 1.4889437807141803e-05\n",
            "Iteration 341/1000, x1: 0.004242336843162775, x2: 1.286892056465149, Loss: 1.4430228475248441e-05\n",
            "Iteration 342/1000, x1: 0.004176405258476734, x2: 1.2868921756744385, Loss: 1.3985181794851087e-05\n",
            "Iteration 343/1000, x1: 0.004111498594284058, x2: 1.2868924140930176, Loss: 1.3553860298998188e-05\n",
            "Iteration 344/1000, x1: 0.00404760055243969, x2: 1.2868926525115967, Loss: 1.3135844710632227e-05\n",
            "Iteration 345/1000, x1: 0.003984695766121149, x2: 1.2868927717208862, Loss: 1.2730718481179792e-05\n",
            "Iteration 346/1000, x1: 0.0039227684028446674, x2: 1.2868928909301758, Loss: 1.233808961842442e-05\n",
            "Iteration 347/1000, x1: 0.003861803561449051, x2: 1.2868930101394653, Loss: 1.195756885863375e-05\n",
            "Iteration 348/1000, x1: 0.003801786107942462, x2: 1.2868932485580444, Loss: 1.1588783308980055e-05\n",
            "Iteration 349/1000, x1: 0.0037427013739943504, x2: 1.286893367767334, Loss: 1.1231371900066733e-05\n",
            "Iteration 350/1000, x1: 0.0036845349241048098, x2: 1.2868934869766235, Loss: 1.0884982657444198e-05\n",
            "Iteration 351/1000, x1: 0.003627272555604577, x2: 1.2868937253952026, Loss: 1.0549276339588687e-05\n",
            "Iteration 352/1000, x1: 0.0035709000658243895, x2: 1.2868938446044922, Loss: 1.022392461891286e-05\n",
            "Iteration 353/1000, x1: 0.0035154037177562714, x2: 1.2868939638137817, Loss: 9.908608262776397e-06\n",
            "Iteration 354/1000, x1: 0.003460769774392247, x2: 1.2868940830230713, Loss: 9.603015314496588e-06\n",
            "Iteration 355/1000, x1: 0.0034069849643856287, x2: 1.2868942022323608, Loss: 9.306847459811252e-06\n",
            "Iteration 356/1000, x1: 0.0033540360163897276, x2: 1.2868943214416504, Loss: 9.019812750921119e-06\n",
            "Iteration 357/1000, x1: 0.0033019098918884993, x2: 1.28689444065094, Loss: 8.741631972952746e-06\n",
            "Iteration 358/1000, x1: 0.0032505940180271864, x2: 1.2868945598602295, Loss: 8.472029549011495e-06\n",
            "Iteration 359/1000, x1: 0.003200075589120388, x2: 1.286894679069519, Loss: 8.210742635128554e-06\n",
            "Iteration 360/1000, x1: 0.0031503422651439905, x2: 1.286894679069519, Loss: 7.957514753798023e-06\n",
            "Iteration 361/1000, x1: 0.003101381938904524, x2: 1.2868947982788086, Loss: 7.712095793976914e-06\n",
            "Iteration 362/1000, x1: 0.003053182503208518, x2: 1.2868949174880981, Loss: 7.474246103811311e-06\n",
            "Iteration 363/1000, x1: 0.0030057320836931467, x2: 1.2868950366973877, Loss: 7.2437323979102075e-06\n",
            "Iteration 364/1000, x1: 0.002959019271656871, x2: 1.2868951559066772, Loss: 7.0203277573455125e-06\n",
            "Iteration 365/1000, x1: 0.0029130324255675077, x2: 1.2868952751159668, Loss: 6.803812993894098e-06\n",
            "Iteration 366/1000, x1: 0.0028677601367235184, x2: 1.2868952751159668, Loss: 6.593976650037803e-06\n",
            "Iteration 367/1000, x1: 0.002823191462084651, x2: 1.2868953943252563, Loss: 6.3906113609846216e-06\n",
            "Iteration 368/1000, x1: 0.002779315458610654, x2: 1.286895513534546, Loss: 6.1935179473948665e-06\n",
            "Iteration 369/1000, x1: 0.002736121416091919, x2: 1.286895513534546, Loss: 6.00250268689706e-06\n",
            "Iteration 370/1000, x1: 0.002693598624318838, x2: 1.2868956327438354, Loss: 5.817379587824689e-06\n",
            "Iteration 371/1000, x1: 0.002651736605912447, x2: 1.286895751953125, Loss: 5.637965386995347e-06\n",
            "Iteration 372/1000, x1: 0.0026105253491550684, x2: 1.286895751953125, Loss: 5.464084097184241e-06\n",
            "Iteration 373/1000, x1: 0.002569954376667738, x2: 1.2868958711624146, Loss: 5.295566097629489e-06\n",
            "Iteration 374/1000, x1: 0.002530013909563422, x2: 1.2868958711624146, Loss: 5.132245405548019e-06\n",
            "Iteration 375/1000, x1: 0.0024906941689550877, x2: 1.286895990371704, Loss: 4.973961040377617e-06\n",
            "Iteration 376/1000, x1: 0.0024519856087863445, x2: 1.2868961095809937, Loss: 4.82055793327163e-06\n",
            "Iteration 377/1000, x1: 0.002413878683000803, x2: 1.2868961095809937, Loss: 4.671886927098967e-06\n",
            "Iteration 378/1000, x1: 0.0023763638455420732, x2: 1.2868962287902832, Loss: 4.527801138465293e-06\n",
            "Iteration 379/1000, x1: 0.0023394322488456964, x2: 1.2868963479995728, Loss: 4.388158231449779e-06\n",
            "Iteration 380/1000, x1: 0.0023030745796859264, x2: 1.2868963479995728, Loss: 4.252823600836564e-06\n",
            "Iteration 381/1000, x1: 0.0022672819904983044, x2: 1.2868963479995728, Loss: 4.1216626414097846e-06\n",
            "Iteration 382/1000, x1: 0.0022320456337183714, x2: 1.2868964672088623, Loss: 3.99454665966914e-06\n",
            "Iteration 383/1000, x1: 0.0021973568946123123, x2: 1.2868964672088623, Loss: 3.871351054840488e-06\n",
            "Iteration 384/1000, x1: 0.002163207158446312, x2: 1.2868964672088623, Loss: 3.7519548641284928e-06\n",
            "Iteration 385/1000, x1: 0.0021295882761478424, x2: 1.2868965864181519, Loss: 3.636240307969274e-06\n",
            "Iteration 386/1000, x1: 0.002096491865813732, x2: 1.2868965864181519, Loss: 3.5240952911408385e-06\n",
            "Iteration 387/1000, x1: 0.0020639097783714533, x2: 1.2868965864181519, Loss: 3.4154090826632455e-06\n",
            "Iteration 388/1000, x1: 0.0020318340975791216, x2: 1.2868967056274414, Loss: 3.3100741347880103e-06\n",
            "Iteration 389/1000, x1: 0.002000256907194853, x2: 1.2868967056274414, Loss: 3.207988356734859e-06\n",
            "Iteration 390/1000, x1: 0.0019691702909767628, x2: 1.2868967056274414, Loss: 3.1090512493392453e-06\n",
            "Iteration 391/1000, x1: 0.0019385669147595763, x2: 1.286896824836731, Loss: 3.0131643597997027e-06\n",
            "Iteration 392/1000, x1: 0.001908439095132053, x2: 1.286896824836731, Loss: 2.920235374404001e-06\n",
            "Iteration 393/1000, x1: 0.0018787794979289174, x2: 1.286896824836731, Loss: 2.830172206813586e-06\n",
            "Iteration 394/1000, x1: 0.0018495809054002166, x2: 1.286896824836731, Loss: 2.742886863416061e-06\n",
            "Iteration 395/1000, x1: 0.0018208360997959971, x2: 1.2868969440460205, Loss: 2.6582931695884326e-06\n",
            "Iteration 396/1000, x1: 0.0017925379797816277, x2: 1.2868969440460205, Loss: 2.576308816060191e-06\n",
            "Iteration 397/1000, x1: 0.0017646796768531203, x2: 1.2868969440460205, Loss: 2.4968530851765536e-06\n",
            "Iteration 398/1000, x1: 0.0017372543225064874, x2: 1.28689706325531, Loss: 2.419847305645817e-06\n",
            "Iteration 399/1000, x1: 0.0017102551646530628, x2: 1.28689706325531, Loss: 2.3452168989024358e-06\n",
            "Iteration 400/1000, x1: 0.0016836756840348244, x2: 1.28689706325531, Loss: 2.2728877411282156e-06\n",
            "Iteration 401/1000, x1: 0.0016575092449784279, x2: 1.2868971824645996, Loss: 2.2027895738574443e-06\n",
            "Iteration 402/1000, x1: 0.0016317494446411729, x2: 1.2868971824645996, Loss: 2.1348532754927874e-06\n",
            "Iteration 403/1000, x1: 0.0016063899965956807, x2: 1.2868971824645996, Loss: 2.069012452921015e-06\n",
            "Iteration 404/1000, x1: 0.0015814247308298945, x2: 1.2868973016738892, Loss: 2.0052018498972757e-06\n",
            "Iteration 405/1000, x1: 0.0015568473609164357, x2: 1.2868973016738892, Loss: 1.943359620781848e-06\n",
            "Iteration 406/1000, x1: 0.001532651949673891, x2: 1.2868973016738892, Loss: 1.8834242609955254e-06\n",
            "Iteration 407/1000, x1: 0.0015088325599208474, x2: 1.2868974208831787, Loss: 1.825337449190556e-06\n",
            "Iteration 408/1000, x1: 0.0014853833708912134, x2: 1.2868974208831787, Loss: 1.769042114574404e-06\n",
            "Iteration 409/1000, x1: 0.0014622986782342196, x2: 1.2868974208831787, Loss: 1.7144828916570987e-06\n",
            "Iteration 410/1000, x1: 0.0014395727775990963, x2: 1.2868975400924683, Loss: 1.6616064613117487e-06\n",
            "Iteration 411/1000, x1: 0.0014171999646350741, x2: 1.2868975400924683, Loss: 1.6103612097140285e-06\n",
            "Iteration 412/1000, x1: 0.001395174884237349, x2: 1.2868975400924683, Loss: 1.5606959777869633e-06\n",
            "Iteration 413/1000, x1: 0.0013734920648857951, x2: 1.2868976593017578, Loss: 1.5125624486245215e-06\n",
            "Iteration 414/1000, x1: 0.0013521462678909302, x2: 1.2868976593017578, Loss: 1.4659133285022108e-06\n",
            "Iteration 415/1000, x1: 0.001331132254563272, x2: 1.2868976593017578, Loss: 1.4207031426849426e-06\n",
            "Iteration 416/1000, x1: 0.0013104447862133384, x2: 1.2868976593017578, Loss: 1.37688732593233e-06\n",
            "Iteration 417/1000, x1: 0.0012900788569822907, x2: 1.2868976593017578, Loss: 1.3344226772460388e-06\n",
            "Iteration 418/1000, x1: 0.0012700294610112906, x2: 1.2868976593017578, Loss: 1.293267928303976e-06\n",
            "Iteration 419/1000, x1: 0.0012502915924414992, x2: 1.2868976593017578, Loss: 1.2533823792182375e-06\n",
            "Iteration 420/1000, x1: 0.0012308604782447219, x2: 1.2868976593017578, Loss: 1.214726808029809e-06\n",
            "Iteration 421/1000, x1: 0.0012117313453927636, x2: 1.2868976593017578, Loss: 1.1772633570217295e-06\n",
            "Iteration 422/1000, x1: 0.0011928995372727513, x2: 1.2868976593017578, Loss: 1.1409554190322524e-06\n",
            "Iteration 423/1000, x1: 0.001174360397271812, x2: 1.2868976593017578, Loss: 1.1057672963943332e-06\n",
            "Iteration 424/1000, x1: 0.0011561093851923943, x2: 1.2868976593017578, Loss: 1.071664314622467e-06\n",
            "Iteration 425/1000, x1: 0.001138141960836947, x2: 1.2868976593017578, Loss: 1.038613163473201e-06\n",
            "Iteration 426/1000, x1: 0.0011204538168385625, x2: 1.2868976593017578, Loss: 1.006581328510947e-06\n",
            "Iteration 427/1000, x1: 0.0011030405294150114, x2: 1.2868976593017578, Loss: 9.75537432168494e-07\n",
            "Iteration 428/1000, x1: 0.001085897907614708, x2: 1.2868976593017578, Loss: 9.454507789996569e-07\n",
            "Iteration 429/1000, x1: 0.0010690216440707445, x2: 1.2868976593017578, Loss: 9.162922083305602e-07\n",
            "Iteration 430/1000, x1: 0.0010524076642468572, x2: 1.2868976593017578, Loss: 8.88032730017585e-07\n",
            "Iteration 431/1000, x1: 0.001036051893606782, x2: 1.2868976593017578, Loss: 8.606448318460025e-07\n",
            "Iteration 432/1000, x1: 0.0010199503740295768, x2: 1.2868976593017578, Loss: 8.341016837221105e-07\n",
            "Iteration 433/1000, x1: 0.0010040990309789777, x2: 1.2868976593017578, Loss: 8.083772513600707e-07\n",
            "Iteration 434/1000, x1: 0.0009884940227493644, x2: 1.2868976593017578, Loss: 7.834460689082334e-07\n",
            "Iteration 435/1000, x1: 0.0009731315658427775, x2: 1.2868976593017578, Loss: 7.592836936964886e-07\n",
            "Iteration 436/1000, x1: 0.0009580078767612576, x2: 1.2868976593017578, Loss: 7.358666493928467e-07\n",
            "Iteration 437/1000, x1: 0.0009431192302145064, x2: 1.2868976593017578, Loss: 7.131718007258314e-07\n",
            "Iteration 438/1000, x1: 0.0009284619591198862, x2: 1.2868976593017578, Loss: 6.911768650752492e-07\n",
            "Iteration 439/1000, x1: 0.0009140325128100812, x2: 1.2868976593017578, Loss: 6.698602419419331e-07\n",
            "Iteration 440/1000, x1: 0.000899827282410115, x2: 1.2868976593017578, Loss: 6.492011266345799e-07\n",
            "Iteration 441/1000, x1: 0.0008858428336679935, x2: 1.2868976593017578, Loss: 6.291791123658186e-07\n",
            "Iteration 442/1000, x1: 0.000872075732331723, x2: 1.2868976593017578, Loss: 6.097746449995611e-07\n",
            "Iteration 443/1000, x1: 0.0008585226023569703, x2: 1.2868976593017578, Loss: 5.909685683036514e-07\n",
            "Iteration 444/1000, x1: 0.0008451800676994026, x2: 1.2868976593017578, Loss: 5.727425218537974e-07\n",
            "Iteration 445/1000, x1: 0.0008320449269376695, x2: 1.2868976593017578, Loss: 5.550785999730579e-07\n",
            "Iteration 446/1000, x1: 0.00081911392044276, x2: 1.2868976593017578, Loss: 5.379594654186803e-07\n",
            "Iteration 447/1000, x1: 0.0008063838467933238, x2: 1.2868976593017578, Loss: 5.21368292538682e-07\n",
            "Iteration 448/1000, x1: 0.0007938516209833324, x2: 1.2868976593017578, Loss: 5.052887104284309e-07\n",
            "Iteration 449/1000, x1: 0.0007815141580067575, x2: 1.2868976593017578, Loss: 4.897051439911593e-07\n",
            "Iteration 450/1000, x1: 0.0007693684310652316, x2: 1.2868976593017578, Loss: 4.746021602386463e-07\n",
            "Iteration 451/1000, x1: 0.000757411471568048, x2: 1.2868976593017578, Loss: 4.599649230385694e-07\n",
            "Iteration 452/1000, x1: 0.0007456403691321611, x2: 1.2868976593017578, Loss: 4.45779136271085e-07\n",
            "Iteration 453/1000, x1: 0.0007340522133745253, x2: 1.2868976593017578, Loss: 4.320309017202817e-07\n",
            "Iteration 454/1000, x1: 0.0007226441521197557, x2: 1.2868976593017578, Loss: 4.1870666223076114e-07\n",
            "Iteration 455/1000, x1: 0.0007114133331924677, x2: 1.2868976593017578, Loss: 4.0579340065960423e-07\n",
            "Iteration 456/1000, x1: 0.0007003570790402591, x2: 1.2868976593017578, Loss: 3.9327829881585785e-07\n",
            "Iteration 457/1000, x1: 0.0006894726539030671, x2: 1.2868976593017578, Loss: 3.811492206295952e-07\n",
            "Iteration 458/1000, x1: 0.0006787573802284896, x2: 1.2868976593017578, Loss: 3.6939420056114614e-07\n",
            "Iteration 459/1000, x1: 0.0006682086386717856, x2: 1.2868976593017578, Loss: 3.580017278181913e-07\n",
            "Iteration 460/1000, x1: 0.0006578238680958748, x2: 1.2868976593017578, Loss: 3.469606042472151e-07\n",
            "Iteration 461/1000, x1: 0.0006476004491560161, x2: 1.2868976593017578, Loss: 3.36260029598634e-07\n",
            "Iteration 462/1000, x1: 0.0006375359371304512, x2: 1.2868976593017578, Loss: 3.258894309965399e-07\n",
            "Iteration 463/1000, x1: 0.0006276278290897608, x2: 1.2868976593017578, Loss: 3.1583869031237555e-07\n",
            "Iteration 464/1000, x1: 0.0006178736803121865, x2: 1.2868976593017578, Loss: 3.060979167912592e-07\n",
            "Iteration 465/1000, x1: 0.0006082711624912918, x2: 1.2868976593017578, Loss: 2.966575323171128e-07\n",
            "Iteration 466/1000, x1: 0.0005988178891129792, x2: 1.2868976593017578, Loss: 2.875083566777903e-07\n",
            "Iteration 467/1000, x1: 0.0005895115318708122, x2: 1.2868976593017578, Loss: 2.786413233479834e-07\n",
            "Iteration 468/1000, x1: 0.0005803497624583542, x2: 1.2868976593017578, Loss: 2.700477637063159e-07\n",
            "Iteration 469/1000, x1: 0.0005713304271921515, x2: 1.2868976593017578, Loss: 2.6171920808337745e-07\n",
            "Iteration 470/1000, x1: 0.0005624512559734285, x2: 1.2868976593017578, Loss: 2.5364755629198044e-07\n",
            "Iteration 471/1000, x1: 0.0005537100369110703, x2: 1.2868976593017578, Loss: 2.4582485025348433e-07\n",
            "Iteration 472/1000, x1: 0.0005451046745292842, x2: 1.2868976593017578, Loss: 2.3824335926292406e-07\n",
            "Iteration 473/1000, x1: 0.0005366330733522773, x2: 1.2868976593017578, Loss: 2.30895679464993e-07\n",
            "Iteration 474/1000, x1: 0.0005282931379042566, x2: 1.2868976593017578, Loss: 2.2377464858891472e-07\n",
            "Iteration 475/1000, x1: 0.0005200827727094293, x2: 1.2868976593017578, Loss: 2.1687320383989572e-07\n",
            "Iteration 476/1000, x1: 0.0005120000569149852, x2: 1.2868976593017578, Loss: 2.1018460927280103e-07\n",
            "Iteration 477/1000, x1: 0.0005040429532527924, x2: 1.2868976593017578, Loss: 2.0370232789446163e-07\n",
            "Iteration 478/1000, x1: 0.0004962094826623797, x2: 1.2868976593017578, Loss: 1.9741997903111042e-07\n",
            "Iteration 479/1000, x1: 0.0004884977824985981, x2: 1.2868976593017578, Loss: 1.9133135253923683e-07\n",
            "Iteration 480/1000, x1: 0.00048090590280480683, x2: 1.2868976593017578, Loss: 1.8543050828156993e-07\n",
            "Iteration 481/1000, x1: 0.00047343201003968716, x2: 1.2868976593017578, Loss: 1.797116482293859e-07\n",
            "Iteration 482/1000, x1: 0.0004660742706619203, x2: 1.2868976593017578, Loss: 1.7416914488421753e-07\n",
            "Iteration 483/1000, x1: 0.00045883088023401797, x2: 1.2868976593017578, Loss: 1.6879758391041833e-07\n",
            "Iteration 484/1000, x1: 0.0004517000634223223, x2: 1.2868976593017578, Loss: 1.6359170729174366e-07\n",
            "Iteration 485/1000, x1: 0.0004446800739970058, x2: 1.2868976593017578, Loss: 1.5854635648793192e-07\n",
            "Iteration 486/1000, x1: 0.00043776919483207166, x2: 1.2868976593017578, Loss: 1.5365662875410635e-07\n",
            "Iteration 487/1000, x1: 0.00043096570880152285, x2: 1.2868976593017578, Loss: 1.4891772082137322e-07\n",
            "Iteration 488/1000, x1: 0.00042426795698702335, x2: 1.2868976593017578, Loss: 1.4432494310767652e-07\n",
            "Iteration 489/1000, x1: 0.0004176743095740676, x2: 1.2868976593017578, Loss: 1.3987381919378095e-07\n",
            "Iteration 490/1000, x1: 0.00041118313674815, x2: 1.2868976593017578, Loss: 1.3555998634728894e-07\n",
            "Iteration 491/1000, x1: 0.00040479283779859543, x2: 1.2868976593017578, Loss: 1.3137918131178594e-07\n",
            "Iteration 492/1000, x1: 0.00039850184111855924, x2: 1.2868976593017578, Loss: 1.2732732557196869e-07\n",
            "Iteration 493/1000, x1: 0.0003923086333088577, x2: 1.2868976593017578, Loss: 1.234004258776622e-07\n",
            "Iteration 494/1000, x1: 0.00038621167186647654, x2: 1.2868976593017578, Loss: 1.1959463108723867e-07\n",
            "Iteration 495/1000, x1: 0.0003802094724960625, x2: 1.2868976593017578, Loss: 1.1590623216761742e-07\n",
            "Iteration 496/1000, x1: 0.00037430055090226233, x2: 1.2868976593017578, Loss: 1.1233156982370929e-07\n",
            "Iteration 497/1000, x1: 0.00036848345189355314, x2: 1.2868976593017578, Loss: 1.0886716950153641e-07\n",
            "Iteration 498/1000, x1: 0.00036275674938224256, x2: 1.2868976593017578, Loss: 1.0550959927968506e-07\n",
            "Iteration 499/1000, x1: 0.0003571190463844687, x2: 1.2868976593017578, Loss: 1.0225557645071603e-07\n",
            "Iteration 500/1000, x1: 0.0003515689750202, x2: 1.2868976593017578, Loss: 9.91019035723184e-08\n",
            "Iteration 501/1000, x1: 0.0003461051674094051, x2: 1.2868976593017578, Loss: 9.604551109987369e-08\n",
            "Iteration 502/1000, x1: 0.0003407262556720525, x2: 1.2868976593017578, Loss: 9.308338633218227e-08\n",
            "Iteration 503/1000, x1: 0.00033543093013577163, x2: 1.2868976593017578, Loss: 9.021260183317281e-08\n",
            "Iteration 504/1000, x1: 0.0003302179102320224, x2: 1.2868976593017578, Loss: 8.74303438536117e-08\n",
            "Iteration 505/1000, x1: 0.0003250859153922647, x2: 1.2868976593017578, Loss: 8.47339052256757e-08\n",
            "Iteration 506/1000, x1: 0.0003200336650479585, x2: 1.2868976593017578, Loss: 8.212063562496041e-08\n",
            "Iteration 507/1000, x1: 0.00031505993683822453, x2: 1.2868976593017578, Loss: 7.958794867590768e-08\n",
            "Iteration 508/1000, x1: 0.00031016350840218365, x2: 1.2868976593017578, Loss: 7.713337879522442e-08\n",
            "Iteration 509/1000, x1: 0.00030534318648278713, x2: 1.2868976593017578, Loss: 7.475451013760903e-08\n",
            "Iteration 510/1000, x1: 0.00030059777782298625, x2: 1.2868976593017578, Loss: 7.244901212288823e-08\n",
            "Iteration 511/1000, x1: 0.0002959261182695627, x2: 1.2868976593017578, Loss: 7.021461811973495e-08\n",
            "Iteration 512/1000, x1: 0.0002913270436692983, x2: 1.2868976593017578, Loss: 6.804913255109568e-08\n",
            "Iteration 513/1000, x1: 0.0002867994480766356, x2: 1.2868976593017578, Loss: 6.595042378876315e-08\n",
            "Iteration 514/1000, x1: 0.0002823422255460173, x2: 1.2868976593017578, Loss: 6.391644546965836e-08\n",
            "Iteration 515/1000, x1: 0.000277954270131886, x2: 1.2868976593017578, Loss: 6.194520096869383e-08\n",
            "Iteration 516/1000, x1: 0.00027363450499251485, x2: 1.2868976593017578, Loss: 6.003475050420093e-08\n",
            "Iteration 517/1000, x1: 0.0002693818823900074, x2: 1.2868976593017578, Loss: 5.818321469064358e-08\n",
            "Iteration 518/1000, x1: 0.00026519535458646715, x2: 1.2868976593017578, Loss: 5.638878874947295e-08\n",
            "Iteration 519/1000, x1: 0.0002610738738439977, x2: 1.2868976593017578, Loss: 5.4649703429277e-08\n",
            "Iteration 520/1000, x1: 0.00025701645063236356, x2: 1.2868976593017578, Loss: 5.2964246322062536e-08\n",
            "Iteration 521/1000, x1: 0.00025302209542132914, x2: 1.2868976593017578, Loss: 5.1330772521396284e-08\n",
            "Iteration 522/1000, x1: 0.00024908981868065894, x2: 1.2868976593017578, Loss: 4.974768330612278e-08\n",
            "Iteration 523/1000, x1: 0.0002452186599839479, x2: 1.2868976593017578, Loss: 4.821341903493703e-08\n",
            "Iteration 524/1000, x1: 0.00024140765890479088, x2: 1.2868976593017578, Loss: 4.672647690995291e-08\n",
            "Iteration 525/1000, x1: 0.00023765588412061334, x2: 1.2868976593017578, Loss: 4.528538610770738e-08\n",
            "Iteration 526/1000, x1: 0.00023396241886075586, x2: 1.2868976593017578, Loss: 4.388874330629733e-08\n",
            "Iteration 527/1000, x1: 0.00023032634635455906, x2: 1.2868976593017578, Loss: 4.253517360552905e-08\n",
            "Iteration 528/1000, x1: 0.00022674679348710924, x2: 1.2868976593017578, Loss: 4.1223344737773004e-08\n",
            "Iteration 529/1000, x1: 0.00022322285803966224, x2: 1.2868976593017578, Loss: 3.9951977726104815e-08\n",
            "Iteration 530/1000, x1: 0.0002197536960011348, x2: 1.2868976593017578, Loss: 3.871981846259587e-08\n",
            "Iteration 531/1000, x1: 0.00021633844880852848, x2: 1.2868976593017578, Loss: 3.752566257730905e-08\n",
            "Iteration 532/1000, x1: 0.00021297627245076, x2: 1.2868976593017578, Loss: 3.636833412201668e-08\n",
            "Iteration 533/1000, x1: 0.0002096663520205766, x2: 1.2868976593017578, Loss: 3.5246696228341534e-08\n",
            "Iteration 534/1000, x1: 0.00020640787261072546, x2: 1.2868976593017578, Loss: 3.415965466047055e-08\n",
            "Iteration 535/1000, x1: 0.00020320003386586905, x2: 1.2868976593017578, Loss: 3.310613649887273e-08\n",
            "Iteration 536/1000, x1: 0.000200042049982585, x2: 1.2868976593017578, Loss: 3.208511145658122e-08\n",
            "Iteration 537/1000, x1: 0.00019693314970936626, x2: 1.2868976593017578, Loss: 3.109557411562491e-08\n",
            "Iteration 538/1000, x1: 0.0001938725617947057, x2: 1.2868976593017578, Loss: 3.0136558137883185e-08\n",
            "Iteration 539/1000, x1: 0.00019085954409092665, x2: 1.2868976593017578, Loss: 2.920711672516063e-08\n",
            "Iteration 540/1000, x1: 0.0001878933544503525, x2: 1.2868976593017578, Loss: 2.830634215911232e-08\n",
            "Iteration 541/1000, x1: 0.00018497325072530657, x2: 1.2868976593017578, Loss: 2.7433349814032226e-08\n",
            "Iteration 542/1000, x1: 0.00018209853442385793, x2: 1.2868976593017578, Loss: 2.6587274604139566e-08\n",
            "Iteration 543/1000, x1: 0.00017926849250216037, x2: 1.2868976593017578, Loss: 2.5767297628931374e-08\n",
            "Iteration 544/1000, x1: 0.00017648244102019817, x2: 1.2868976593017578, Loss: 2.4972607093332044e-08\n",
            "Iteration 545/1000, x1: 0.00017373968148604035, x2: 1.2868976593017578, Loss: 2.4202430282116438e-08\n",
            "Iteration 546/1000, x1: 0.00017103954451158643, x2: 1.2868976593017578, Loss: 2.3456003361843614e-08\n",
            "Iteration 547/1000, x1: 0.0001683813752606511, x2: 1.2868976593017578, Loss: 2.2732596249852577e-08\n",
            "Iteration 548/1000, x1: 0.00016576451889704913, x2: 1.2868976593017578, Loss: 2.2031501956121247e-08\n",
            "Iteration 549/1000, x1: 0.00016318833513651043, x2: 1.2868976593017578, Loss: 2.1352029477839096e-08\n",
            "Iteration 550/1000, x1: 0.00016065218369476497, x2: 1.2868976593017578, Loss: 2.069351268119135e-08\n",
            "Iteration 551/1000, x1: 0.00015815545339137316, x2: 1.2868976593017578, Loss: 2.005530319593163e-08\n",
            "Iteration 552/1000, x1: 0.00015569751849398017, x2: 1.2868976593017578, Loss: 1.943678107352298e-08\n",
            "Iteration 553/1000, x1: 0.00015327778237406164, x2: 1.2868976593017578, Loss: 1.883733169449897e-08\n",
            "Iteration 554/1000, x1: 0.00015089564840309322, x2: 1.2868976593017578, Loss: 1.82563688611026e-08\n",
            "Iteration 555/1000, x1: 0.00014855053450446576, x2: 1.2868976593017578, Loss: 1.769332413914526e-08\n",
            "Iteration 556/1000, x1: 0.00014624187315348536, x2: 1.2868976593017578, Loss: 1.714764330529306e-08\n",
            "Iteration 557/1000, x1: 0.0001439690968254581, x2: 1.2868976593017578, Loss: 1.6618793452494174e-08\n",
            "Iteration 558/1000, x1: 0.0001417316379956901, x2: 1.2868976593017578, Loss: 1.6106254108194662e-08\n",
            "Iteration 559/1000, x1: 0.0001395289582433179, x2: 1.2868976593017578, Loss: 1.5609520787052134e-08\n",
            "Iteration 560/1000, x1: 0.00013736050459556282, x2: 1.2868976593017578, Loss: 1.512811209636311e-08\n",
            "Iteration 561/1000, x1: 0.00013522575318347663, x2: 1.2868976593017578, Loss: 1.4661544867067278e-08\n",
            "Iteration 562/1000, x1: 0.00013312418013811111, x2: 1.2868976593017578, Loss: 1.4209368792705845e-08\n",
            "Iteration 563/1000, x1: 0.00013105526159051806, x2: 1.2868976593017578, Loss: 1.3771139784068964e-08\n",
            "Iteration 564/1000, x1: 0.0001290185027755797, x2: 1.2868976593017578, Loss: 1.334642441008782e-08\n",
            "Iteration 565/1000, x1: 0.00012701339437626302, x2: 1.2868976593017578, Loss: 1.2934807891440414e-08\n",
            "Iteration 566/1000, x1: 0.0001250394416274503, x2: 1.2868976593017578, Loss: 1.2535886106945782e-08\n",
            "Iteration 567/1000, x1: 0.00012309617886785418, x2: 1.2868976593017578, Loss: 1.2149266481742416e-08\n",
            "Iteration 568/1000, x1: 0.00012118311133235693, x2: 1.2868976593017578, Loss: 1.1774571540001944e-08\n",
            "Iteration 569/1000, x1: 0.00011929977335967124, x2: 1.2868976593017578, Loss: 1.141143268768019e-08\n",
            "Iteration 570/1000, x1: 0.0001174457065644674, x2: 1.2868976593017578, Loss: 1.1059492877052435e-08\n",
            "Iteration 571/1000, x1: 0.00011562045256141573, x2: 1.2868976593017578, Loss: 1.0718408383070255e-08\n",
            "Iteration 572/1000, x1: 0.00011382356751710176, x2: 1.2868976593017578, Loss: 1.0387841697934164e-08\n",
            "Iteration 573/1000, x1: 0.00011205460759811103, x2: 1.2868976593017578, Loss: 1.006747041287781e-08\n",
            "Iteration 574/1000, x1: 0.00011031313624698669, x2: 1.2868976593017578, Loss: 9.75698011274062e-09\n",
            "Iteration 575/1000, x1: 0.0001085987314581871, x2: 1.2868976593017578, Loss: 9.456064375967799e-09\n",
            "Iteration 576/1000, x1: 0.00010691097122617066, x2: 1.2868976593017578, Loss: 9.164430991859263e-09\n",
            "Iteration 577/1000, x1: 0.00010524944082135335, x2: 1.2868976593017578, Loss: 8.88179041425019e-09\n",
            "Iteration 578/1000, x1: 0.00010361373279010877, x2: 1.2868976593017578, Loss: 8.607867307830475e-09\n",
            "Iteration 579/1000, x1: 0.00010200344695476815, x2: 1.2868976593017578, Loss: 8.342392554538947e-09\n",
            "Iteration 580/1000, x1: 0.00010041818313766271, x2: 1.2868976593017578, Loss: 8.085105029920214e-09\n",
            "Iteration 581/1000, x1: 9.885755571303889e-05, x2: 1.2868976593017578, Loss: 7.835752491303083e-09\n",
            "Iteration 582/1000, x1: 9.732118633110076e-05, x2: 1.2868976593017578, Loss: 7.594089801443715e-09\n",
            "Iteration 583/1000, x1: 9.580869664205238e-05, x2: 1.2868976593017578, Loss: 7.359880704882471e-09\n",
            "Iteration 584/1000, x1: 9.431970829609782e-05, x2: 1.2868976593017578, Loss: 7.132895163408648e-09\n",
            "Iteration 585/1000, x1: 9.285386477131397e-05, x2: 1.2868976593017578, Loss: 6.912909800149691e-09\n",
            "Iteration 586/1000, x1: 9.141080226982012e-05, x2: 1.2868976593017578, Loss: 6.699709231838824e-09\n",
            "Iteration 587/1000, x1: 8.99901642696932e-05, x2: 1.2868976593017578, Loss: 6.493083848368997e-09\n",
            "Iteration 588/1000, x1: 8.85916015249677e-05, x2: 1.2868976593017578, Loss: 6.292831145060518e-09\n",
            "Iteration 589/1000, x1: 8.721477934159338e-05, x2: 1.2868976593017578, Loss: 6.098753946304214e-09\n",
            "Iteration 590/1000, x1: 8.585935574956238e-05, x2: 1.2868976593017578, Loss: 5.910662626007479e-09\n",
            "Iteration 591/1000, x1: 8.452499605482444e-05, x2: 1.2868976593017578, Loss: 5.7283724430590155e-09\n",
            "Iteration 592/1000, x1: 8.321137283928692e-05, x2: 1.2868976593017578, Loss: 5.551703985418044e-09\n",
            "Iteration 593/1000, x1: 8.19181659608148e-05, x2: 1.2868976593017578, Loss: 5.380484058292723e-09\n",
            "Iteration 594/1000, x1: 8.064505527727306e-05, x2: 1.2868976593017578, Loss: 5.2145452400509384e-09\n",
            "Iteration 595/1000, x1: 7.939172792248428e-05, x2: 1.2868976593017578, Loss: 5.053723217685047e-09\n",
            "Iteration 596/1000, x1: 7.815787830622867e-05, x2: 1.2868976593017578, Loss: 4.89786167179318e-09\n",
            "Iteration 597/1000, x1: 7.694320811424404e-05, x2: 1.2868976593017578, Loss: 4.746806503419521e-09\n",
            "Iteration 598/1000, x1: 7.574741175631061e-05, x2: 1.2868976593017578, Loss: 4.600410274946398e-09\n",
            "Iteration 599/1000, x1: 7.457020547008142e-05, x2: 1.2868976593017578, Loss: 4.4585286573806115e-09\n",
            "Iteration 600/1000, x1: 7.341129094129428e-05, x2: 1.2868976593017578, Loss: 4.321023983067107e-09\n",
            "Iteration 601/1000, x1: 7.227038440760225e-05, x2: 1.2868976593017578, Loss: 4.187759028440041e-09\n",
            "Iteration 602/1000, x1: 7.114720938261598e-05, x2: 1.2868976593017578, Loss: 4.058604119450138e-09\n",
            "Iteration 603/1000, x1: 7.004148937994614e-05, x2: 1.2868976593017578, Loss: 3.933432690672589e-09\n",
            "Iteration 604/1000, x1: 6.8952955189161e-05, x2: 1.2868976593017578, Loss: 3.812121729396267e-09\n",
            "Iteration 605/1000, x1: 6.788133759982884e-05, x2: 1.2868976593017578, Loss: 3.6945517756237223e-09\n",
            "Iteration 606/1000, x1: 6.682637467747554e-05, x2: 1.2868976593017578, Loss: 3.580607810249603e-09\n",
            "Iteration 607/1000, x1: 6.578781176358461e-05, x2: 1.2868976593017578, Loss: 3.4701781448376323e-09\n",
            "Iteration 608/1000, x1: 6.476538692368194e-05, x2: 1.2868976593017578, Loss: 3.3631548657098165e-09\n",
            "Iteration 609/1000, x1: 6.375885277520865e-05, x2: 1.2868976593017578, Loss: 3.2594320575896063e-09\n",
            "Iteration 610/1000, x1: 6.276796193560585e-05, x2: 1.2868976593017578, Loss: 3.158908024047946e-09\n",
            "Iteration 611/1000, x1: 6.179246702231467e-05, x2: 1.2868976593017578, Loss: 3.0614841772802492e-09\n",
            "Iteration 612/1000, x1: 6.083213520469144e-05, x2: 1.2868976593017578, Loss: 2.967064816061793e-09\n",
            "Iteration 613/1000, x1: 5.98867263761349e-05, x2: 1.2868976593017578, Loss: 2.8755580139261383e-09\n",
            "Iteration 614/1000, x1: 5.895601134398021e-05, x2: 1.2868976593017578, Loss: 2.786872732585266e-09\n",
            "Iteration 615/1000, x1: 5.803976091556251e-05, x2: 1.2868976593017578, Loss: 2.700922818732465e-09\n",
            "Iteration 616/1000, x1: 5.713774953619577e-05, x2: 1.2868976593017578, Loss: 2.6176236733732594e-09\n",
            "Iteration 617/1000, x1: 5.624975892715156e-05, x2: 1.2868976593017578, Loss: 2.5368935840930362e-09\n",
            "Iteration 618/1000, x1: 5.537556717172265e-05, x2: 1.2868976593017578, Loss: 2.4586535030124423e-09\n",
            "Iteration 619/1000, x1: 5.451496326713823e-05, x2: 1.2868976593017578, Loss: 2.382826158608964e-09\n",
            "Iteration 620/1000, x1: 5.3667732572648674e-05, x2: 1.2868976593017578, Loss: 2.3093376100291607e-09\n",
            "Iteration 621/1000, x1: 5.2833667723461986e-05, x2: 1.2868976593017578, Loss: 2.2381154707318274e-09\n",
            "Iteration 622/1000, x1: 5.2012564992764965e-05, x2: 1.2868976593017578, Loss: 2.1690897966664124e-09\n",
            "Iteration 623/1000, x1: 5.120422429172322e-05, x2: 1.2868976593017578, Loss: 2.102192642183809e-09\n",
            "Iteration 624/1000, x1: 5.0408445531502366e-05, x2: 1.2868976593017578, Loss: 2.0373589482147736e-09\n",
            "Iteration 625/1000, x1: 4.962503589922562e-05, x2: 1.2868976593017578, Loss: 1.9745247659130882e-09\n",
            "Iteration 626/1000, x1: 4.885379894403741e-05, x2: 1.2868976593017578, Loss: 1.9136285889231885e-09\n",
            "Iteration 627/1000, x1: 4.809454912901856e-05, x2: 1.2868976593017578, Loss: 1.8546103541794423e-09\n",
            "Iteration 628/1000, x1: 4.734710091724992e-05, x2: 1.2868976593017578, Loss: 1.797412330084569e-09\n",
            "Iteration 629/1000, x1: 4.661126877181232e-05, x2: 1.2868976593017578, Loss: 1.7419783393535226e-09\n",
            "Iteration 630/1000, x1: 4.588687079376541e-05, x2: 1.2868976593017578, Loss: 1.6882542031027015e-09\n",
            "Iteration 631/1000, x1: 4.517373236012645e-05, x2: 1.2868976593017578, Loss: 1.6361866306269235e-09\n",
            "Iteration 632/1000, x1: 4.447167520993389e-05, x2: 1.2868976593017578, Loss: 1.5857252178008707e-09\n",
            "Iteration 633/1000, x1: 4.37805283581838e-05, x2: 1.2868976593017578, Loss: 1.5368198935661326e-09\n",
            "Iteration 634/1000, x1: 4.310012445785105e-05, x2: 1.2868976593017578, Loss: 1.4894228073103477e-09\n",
            "Iteration 635/1000, x1: 4.243029616191052e-05, x2: 1.2868976593017578, Loss: 1.4434875517110868e-09\n",
            "Iteration 636/1000, x1: 4.1770876123337075e-05, x2: 1.2868976593017578, Loss: 1.39896905171355e-09\n",
            "Iteration 637/1000, x1: 4.112170427106321e-05, x2: 1.2868976593017578, Loss: 1.3558234535082647e-09\n",
            "Iteration 638/1000, x1: 4.048262053402141e-05, x2: 1.2868976593017578, Loss: 1.3140085686202951e-09\n",
            "Iteration 639/1000, x1: 3.9853468479122967e-05, x2: 1.2868976593017578, Loss: 1.2734832077754277e-09\n",
            "Iteration 640/1000, x1: 3.923409531125799e-05, x2: 1.2868976593017578, Loss: 1.2342076249893807e-09\n",
            "Iteration 641/1000, x1: 3.8624348235316575e-05, x2: 1.2868976593017578, Loss: 1.1961435175678048e-09\n",
            "Iteration 642/1000, x1: 3.8024078094167635e-05, x2: 1.2868976593017578, Loss: 1.159253248950165e-09\n",
            "Iteration 643/1000, x1: 3.743313573068008e-05, x2: 1.2868976593017578, Loss: 1.1235008479104636e-09\n",
            "Iteration 644/1000, x1: 3.685137926368043e-05, x2: 1.2868976593017578, Loss: 1.0888508983342149e-09\n",
            "Iteration 645/1000, x1: 3.62786631740164e-05, x2: 1.2868976593017578, Loss: 1.0552697604637729e-09\n",
            "Iteration 646/1000, x1: 3.571484558051452e-05, x2: 1.2868976593017578, Loss: 1.0227242386307012e-09\n",
            "Iteration 647/1000, x1: 3.5159791877958924e-05, x2: 1.2868976593017578, Loss: 9.911823584118906e-10\n",
            "Iteration 648/1000, x1: 3.461336382315494e-05, x2: 1.2868976593017578, Loss: 9.606132556072566e-10\n",
            "Iteration 649/1000, x1: 3.407543044886552e-05, x2: 1.2868976593017578, Loss: 9.309869541951343e-10\n",
            "Iteration 650/1000, x1: 3.354585714987479e-05, x2: 1.2868976593017578, Loss: 9.022745328657322e-10\n",
            "Iteration 651/1000, x1: 3.3024512958945706e-05, x2: 1.2868976593017578, Loss: 8.744475699096199e-10\n",
            "Iteration 652/1000, x1: 3.2511270546820015e-05, x2: 1.2868976593017578, Loss: 8.474788093515428e-10\n",
            "Iteration 653/1000, x1: 3.2006006222218275e-05, x2: 1.2868976593017578, Loss: 8.213417168612125e-10\n",
            "Iteration 654/1000, x1: 3.150859265588224e-05, x2: 1.2868976593017578, Loss: 7.960108128202137e-10\n",
            "Iteration 655/1000, x1: 3.1018909794511274e-05, x2: 1.2868976593017578, Loss: 7.714610616993411e-10\n",
            "Iteration 656/1000, x1: 3.0536837584804744e-05, x2: 1.2868976593017578, Loss: 7.47668482681263e-10\n",
            "Iteration 657/1000, x1: 3.006225779245142e-05, x2: 1.2868976593017578, Loss: 7.246095945490083e-10\n",
            "Iteration 658/1000, x1: 2.959505218314007e-05, x2: 1.2868976593017578, Loss: 7.02262026308631e-10\n",
            "Iteration 659/1000, x1: 2.9135107979527675e-05, x2: 1.2868976593017578, Loss: 6.806035179884873e-10\n",
            "Iteration 660/1000, x1: 2.8682312404271215e-05, x2: 1.2868976593017578, Loss: 6.596130863734118e-10\n",
            "Iteration 661/1000, x1: 2.823655268002767e-05, x2: 1.2868976593017578, Loss: 6.392699702928439e-10\n",
            "Iteration 662/1000, x1: 2.7797721486422233e-05, x2: 1.2868976593017578, Loss: 6.195542412434918e-10\n",
            "Iteration 663/1000, x1: 2.736570968409069e-05, x2: 1.2868976593017578, Loss: 6.004466368558781e-10\n",
            "Iteration 664/1000, x1: 2.6940411771647632e-05, x2: 1.2868976593017578, Loss: 5.819282278274329e-10\n",
            "Iteration 665/1000, x1: 2.652172406669706e-05, x2: 1.2868976593017578, Loss: 5.639809730340062e-10\n",
            "Iteration 666/1000, x1: 2.6109542886842974e-05, x2: 1.2868976593017578, Loss: 5.465872199295063e-10\n",
            "Iteration 667/1000, x1: 2.5703768187668175e-05, x2: 1.2868976593017578, Loss: 5.297299821016566e-10\n",
            "Iteration 668/1000, x1: 2.530429992475547e-05, x2: 1.2868976593017578, Loss: 5.133925506939363e-10\n",
            "Iteration 669/1000, x1: 2.4911039872677065e-05, x2: 1.2868976593017578, Loss: 4.975590495170934e-10\n",
            "Iteration 670/1000, x1: 2.4523891624994576e-05, x2: 1.2868976593017578, Loss: 4.822138799376319e-10\n",
            "Iteration 671/1000, x1: 2.4142758775269613e-05, x2: 1.2868976593017578, Loss: 4.673419429224168e-10\n",
            "Iteration 672/1000, x1: 2.3767550374031998e-05, x2: 1.2868976593017578, Loss: 4.529286390386744e-10\n",
            "Iteration 673/1000, x1: 2.3398173652822152e-05, x2: 1.2868976593017578, Loss: 4.3895989620956755e-10\n",
            "Iteration 674/1000, x1: 2.3034537662169896e-05, x2: 1.2868976593017578, Loss: 4.2542194766959085e-10\n",
            "Iteration 675/1000, x1: 2.2676551452605054e-05, x2: 1.2868976593017578, Loss: 4.123015540091757e-10\n",
            "Iteration 676/1000, x1: 2.2324129531625658e-05, x2: 1.2868976593017578, Loss: 3.9958578113008514e-10\n",
            "Iteration 677/1000, x1: 2.197718458774034e-05, x2: 1.2868976593017578, Loss: 3.872621390232922e-10\n",
            "Iteration 678/1000, x1: 2.163563112844713e-05, x2: 1.2868976593017578, Loss: 3.753186095245553e-10\n",
            "Iteration 679/1000, x1: 2.1299385480233468e-05, x2: 1.2868976593017578, Loss: 3.6374342426981343e-10\n",
            "Iteration 680/1000, x1: 2.0968365788576193e-05, x2: 1.2868976593017578, Loss: 3.5252517571748854e-10\n",
            "Iteration 681/1000, x1: 2.064249201794155e-05, x2: 1.2868976593017578, Loss: 3.4165292817078807e-10\n",
            "Iteration 682/1000, x1: 2.0321682313806377e-05, x2: 1.2868976593017578, Loss: 3.3111605124425125e-10\n",
            "Iteration 683/1000, x1: 2.0005858459626324e-05, x2: 1.2868976593017578, Loss: 3.209041365970222e-10\n",
            "Iteration 684/1000, x1: 1.969494223885704e-05, x2: 1.2868976593017578, Loss: 3.110071367107281e-10\n",
            "Iteration 685/1000, x1: 1.9388859072932974e-05, x2: 1.2868976593017578, Loss: 3.014153926450547e-10\n",
            "Iteration 686/1000, x1: 1.908753256429918e-05, x2: 1.2868976593017578, Loss: 2.9211946750429263e-10\n",
            "Iteration 687/1000, x1: 1.8790888134390116e-05, x2: 1.2868976593017578, Loss: 2.831102297040644e-10\n",
            "Iteration 688/1000, x1: 1.849885484261904e-05, x2: 1.2868976593017578, Loss: 2.7437882521574863e-10\n",
            "Iteration 689/1000, x1: 1.821135992940981e-05, x2: 1.2868976593017578, Loss: 2.659167330776313e-10\n",
            "Iteration 690/1000, x1: 1.792833245417569e-05, x2: 1.2868976593017578, Loss: 2.5771562661702774e-10\n",
            "Iteration 691/1000, x1: 1.764970329531934e-05, x2: 1.2868976593017578, Loss: 2.497674289614338e-10\n",
            "Iteration 692/1000, x1: 1.7375405150232837e-05, x2: 1.2868976593017578, Loss: 2.4206434079410144e-10\n",
            "Iteration 693/1000, x1: 1.710536889731884e-05, x2: 1.2868976593017578, Loss: 2.345988403540389e-10\n",
            "Iteration 694/1000, x1: 1.6839530871948227e-05, x2: 1.2868976593017578, Loss: 2.2736357241370797e-10\n",
            "Iteration 695/1000, x1: 1.6577823771513067e-05, x2: 1.2868976593017578, Loss: 2.2035148705690233e-10\n",
            "Iteration 696/1000, x1: 1.6320183931384236e-05, x2: 1.2868976593017578, Loss: 2.1355563151193024e-10\n",
            "Iteration 697/1000, x1: 1.606654768693261e-05, x2: 1.2868976593017578, Loss: 2.069693860740074e-10\n",
            "Iteration 698/1000, x1: 1.5816853192518465e-05, x2: 1.2868976593017578, Loss: 2.005862420606519e-10\n",
            "Iteration 699/1000, x1: 1.5571038602502085e-05, x2: 1.2868976593017578, Loss: 1.9439995446735026e-10\n",
            "Iteration 700/1000, x1: 1.5329045709222555e-05, x2: 1.2868976593017578, Loss: 1.8840445870083045e-10\n",
            "Iteration 701/1000, x1: 1.5090813576534856e-05, x2: 1.2868976593017578, Loss: 1.8259388445684976e-10\n",
            "Iteration 702/1000, x1: 1.4856283087283373e-05, x2: 1.2868976593017578, Loss: 1.769625140868314e-10\n",
            "Iteration 703/1000, x1: 1.4625397852796596e-05, x2: 1.2868976593017578, Loss: 1.7150481035344e-10\n",
            "Iteration 704/1000, x1: 1.4398100574908312e-05, x2: 1.2868976593017578, Loss: 1.662154303083696e-10\n",
            "Iteration 705/1000, x1: 1.4174335774441715e-05, x2: 1.2868976593017578, Loss: 1.6108918365898006e-10\n",
            "Iteration 706/1000, x1: 1.3954048881714698e-05, x2: 1.2868976593017578, Loss: 1.5612104664608495e-10\n",
            "Iteration 707/1000, x1: 1.3737185327045154e-05, x2: 1.2868976593017578, Loss: 1.513061065328003e-10\n",
            "Iteration 708/1000, x1: 1.352369235974038e-05, x2: 1.2868976593017578, Loss: 1.4663967262684707e-10\n",
            "Iteration 709/1000, x1: 1.3313517229107674e-05, x2: 1.2868976593017578, Loss: 1.421171791360365e-10\n",
            "Iteration 710/1000, x1: 1.3106608093949035e-05, x2: 1.2868976593017578, Loss: 1.3773414353490665e-10\n",
            "Iteration 711/1000, x1: 1.2902914932055864e-05, x2: 1.2868976593017578, Loss: 1.3348627758702492e-10\n",
            "Iteration 712/1000, x1: 1.2702387721219566e-05, x2: 1.2868976593017578, Loss: 1.2936943183383676e-10\n",
            "Iteration 713/1000, x1: 1.2504976439231541e-05, x2: 1.2868976593017578, Loss: 1.253795539613023e-10\n",
            "Iteration 714/1000, x1: 1.2310633792367298e-05, x2: 1.2868976593017578, Loss: 1.2151273043325972e-10\n",
            "Iteration 715/1000, x1: 1.2119311577407643e-05, x2: 1.2868976593017578, Loss: 1.177651587358497e-10\n",
            "Iteration 716/1000, x1: 1.1930962500628084e-05, x2: 1.2868976593017578, Loss: 1.1413317513309096e-10\n",
            "Iteration 717/1000, x1: 1.174554017779883e-05, x2: 1.2868976593017578, Loss: 1.1061319915572909e-10\n",
            "Iteration 718/1000, x1: 1.1563000043679494e-05, x2: 1.2868976593017578, Loss: 1.0720177523459995e-10\n",
            "Iteration 719/1000, x1: 1.1383296623534989e-05, x2: 1.2868976593017578, Loss: 1.0389557270062966e-10\n",
            "Iteration 720/1000, x1: 1.1206386261619627e-05, x2: 1.2868976593017578, Loss: 1.0069133721257728e-10\n",
            "Iteration 721/1000, x1: 1.1032225302187726e-05, x2: 1.2868976593017578, Loss: 9.758592545150435e-11\n",
            "Iteration 722/1000, x1: 1.08607709989883e-05, x2: 1.2868976593017578, Loss: 9.457627736519925e-11\n",
            "Iteration 723/1000, x1: 1.0691980605770368e-05, x2: 1.2868976593017578, Loss: 9.165946474043452e-11\n",
            "Iteration 724/1000, x1: 1.052581410476705e-05, x2: 1.2868976593017578, Loss: 8.883258711955833e-11\n",
            "Iteration 725/1000, x1: 1.0362229659222066e-05, x2: 1.2868976593017578, Loss: 8.609291057837254e-11\n",
            "Iteration 726/1000, x1: 1.0201187251368538e-05, x2: 1.2868976593017578, Loss: 8.343771507046682e-11\n",
            "Iteration 727/1000, x1: 1.0042647772934288e-05, x2: 1.2868976593017578, Loss: 8.086441238841502e-11\n",
            "Iteration 728/1000, x1: 9.886572115647141e-06, x2: 1.2868976593017578, Loss: 7.83704698359422e-11\n",
            "Iteration 729/1000, x1: 9.732922080729622e-06, x2: 1.2868976593017578, Loss: 7.59534379835003e-11\n",
            "Iteration 730/1000, x1: 9.58166037889896e-06, x2: 1.2868976593017578, Loss: 7.361095760716196e-11\n",
            "Iteration 731/1000, x1: 9.43274972087238e-06, x2: 1.2868976593017578, Loss: 7.134072499415112e-11\n",
            "Iteration 732/1000, x1: 9.28615281736711e-06, x2: 1.2868976593017578, Loss: 6.91405196984185e-11\n",
            "Iteration 733/1000, x1: 9.141834198089782e-06, x2: 1.2868976593017578, Loss: 6.700814902949048e-11\n",
            "Iteration 734/1000, x1: 8.999758392747026e-06, x2: 1.2868976593017578, Loss: 6.49415521358776e-11\n",
            "Iteration 735/1000, x1: 8.859890840540174e-06, x2: 1.2868976593017578, Loss: 6.29386889827721e-11\n",
            "Iteration 736/1000, x1: 8.72219698067056e-06, x2: 1.2868976593017578, Loss: 6.09975958631992e-11\n",
            "Iteration 737/1000, x1: 8.586643161834218e-06, x2: 1.2868976593017578, Loss: 5.91163715202292e-11\n",
            "Iteration 738/1000, x1: 8.453195732727181e-06, x2: 1.2868976593017578, Loss: 5.729316326918976e-11\n",
            "Iteration 739/1000, x1: 8.321822861034889e-06, x2: 1.2868976593017578, Loss: 5.5526187814347594e-11\n",
            "Iteration 740/1000, x1: 8.192490895453375e-06, x2: 1.2868976593017578, Loss: 5.381370696277976e-11\n",
            "Iteration 741/1000, x1: 8.065168913162779e-06, x2: 1.2868976593017578, Loss: 5.215403803271457e-11\n",
            "Iteration 742/1000, x1: 7.939825991343241e-06, x2: 1.2868976593017578, Loss: 5.054554691463764e-11\n",
            "Iteration 743/1000, x1: 7.816431207174901e-06, x2: 1.2868976593017578, Loss: 4.8986675826867554e-11\n",
            "Iteration 744/1000, x1: 7.694953637837898e-06, x2: 1.2868976593017578, Loss: 4.747588086551069e-11\n",
            "Iteration 745/1000, x1: 7.5753646342491265e-06, x2: 1.2868976593017578, Loss: 4.6011670168377705e-11\n",
            "Iteration 746/1000, x1: 7.457634183083428e-06, x2: 1.2868976593017578, Loss: 4.4592628201112205e-11\n",
            "Iteration 747/1000, x1: 7.341733180510346e-06, x2: 1.2868976593017578, Loss: 4.321734983769865e-11\n",
            "Iteration 748/1000, x1: 7.227633432194125e-06, x2: 1.2868976593017578, Loss: 4.1884485463272725e-11\n",
            "Iteration 749/1000, x1: 7.11530674379901e-06, x2: 1.2868976593017578, Loss: 4.059272709633355e-11\n",
            "Iteration 750/1000, x1: 7.004725830483949e-06, x2: 1.2868976593017578, Loss: 3.93408049192967e-11\n",
            "Iteration 751/1000, x1: 6.895863407407887e-06, x2: 1.2868976593017578, Loss: 3.812749421738815e-11\n",
            "Iteration 752/1000, x1: 6.788693099224474e-06, x2: 1.2868976593017578, Loss: 3.6951604970303364e-11\n",
            "Iteration 753/1000, x1: 6.683188530587358e-06, x2: 1.2868976593017578, Loss: 3.581198185220735e-11\n",
            "Iteration 754/1000, x1: 6.579323326150188e-06, x2: 1.2868976593017578, Loss: 3.470750423173463e-11\n",
            "Iteration 755/1000, x1: 6.477072474808665e-06, x2: 1.2868976593017578, Loss: 3.363709311088314e-11\n",
            "Iteration 756/1000, x1: 6.376410510711139e-06, x2: 1.2868976593017578, Loss: 3.259969377777949e-11\n",
            "Iteration 757/1000, x1: 6.2773133322480135e-06, x2: 1.2868976593017578, Loss: 3.1594286215019807e-11\n",
            "Iteration 758/1000, x1: 6.1797559283149894e-06, x2: 1.2868976593017578, Loss: 3.061988856911668e-11\n",
            "Iteration 759/1000, x1: 6.083714652049821e-06, x2: 1.2868976593017578, Loss: 2.967553980326443e-11\n",
            "Iteration 760/1000, x1: 5.9891663113376126e-06, x2: 1.2868976593017578, Loss: 2.8760317044573824e-11\n",
            "Iteration 761/1000, x1: 5.8960872593161184e-06, x2: 1.2868976593017578, Loss: 2.7873321706284315e-11\n",
            "Iteration 762/1000, x1: 5.804454758617794e-06, x2: 1.2868976593017578, Loss: 2.701368295721096e-11\n",
            "Iteration 763/1000, x1: 5.714246071875095e-06, x2: 1.2868976593017578, Loss: 2.618055598702096e-11\n",
            "Iteration 764/1000, x1: 5.6254393712151796e-06, x2: 1.2868976593017578, Loss: 2.5373120271510174e-11\n",
            "Iteration 765/1000, x1: 5.538012828765204e-06, x2: 1.2868976593017578, Loss: 2.4590586511497037e-11\n",
            "Iteration 766/1000, x1: 5.4519450713996775e-06, x2: 1.2868976593017578, Loss: 2.383218622448169e-11\n",
            "Iteration 767/1000, x1: 5.367215180740459e-06, x2: 1.2868976593017578, Loss: 2.3097178683539887e-11\n",
            "Iteration 768/1000, x1: 5.2838017836620566e-06, x2: 1.2868976593017578, Loss: 2.238484050898215e-11\n",
            "Iteration 769/1000, x1: 5.2016848712810315e-06, x2: 1.2868976593017578, Loss: 2.169446913780071e-11\n",
            "Iteration 770/1000, x1: 5.120843979966594e-06, x2: 1.2868976593017578, Loss: 2.1025391497286883e-11\n",
            "Iteration 771/1000, x1: 5.041259555582656e-06, x2: 1.2868976593017578, Loss: 2.0376944923072848e-11\n",
            "Iteration 772/1000, x1: 4.9629120439931285e-06, x2: 1.2868976593017578, Loss: 1.9748499710536827e-11\n",
            "Iteration 773/1000, x1: 4.885782345809275e-06, x2: 1.2868976593017578, Loss: 1.9139436563397894e-11\n",
            "Iteration 774/1000, x1: 4.809851361642359e-06, x2: 1.2868976593017578, Loss: 1.8549158736780313e-11\n",
            "Iteration 775/1000, x1: 4.735100446850993e-06, x2: 1.2868976593017578, Loss: 1.7977085098319634e-11\n",
            "Iteration 776/1000, x1: 4.661510956793791e-06, x2: 1.2868976593017578, Loss: 1.742265706705659e-11\n",
            "Iteration 777/1000, x1: 4.589065156324068e-06, x2: 1.2868976593017578, Loss: 1.68853247356493e-11\n",
            "Iteration 778/1000, x1: 4.51774531029514e-06, x2: 1.2868976593017578, Loss: 1.6364564217608013e-11\n",
            "Iteration 779/1000, x1: 4.447533683560323e-06, x2: 1.2868976593017578, Loss: 1.585986376950732e-11\n",
            "Iteration 780/1000, x1: 4.378413450467633e-06, x2: 1.2868976593017578, Loss: 1.537072899515657e-11\n",
            "Iteration 781/1000, x1: 4.310367330617737e-06, x2: 1.2868976593017578, Loss: 1.4896681110876386e-11\n",
            "Iteration 782/1000, x1: 4.243378953106003e-06, x2: 1.2868976593017578, Loss: 1.4437252608689999e-11\n",
            "Iteration 783/1000, x1: 4.177431492280448e-06, x2: 1.2868976593017578, Loss: 1.3991994195217128e-11\n",
            "Iteration 784/1000, x1: 4.112509031983791e-06, x2: 1.2868976593017578, Loss: 1.3560466985418351e-11\n",
            "Iteration 785/1000, x1: 4.048595656058751e-06, x2: 1.2868976593017578, Loss: 1.3142249441489007e-11\n",
            "Iteration 786/1000, x1: 3.985675448348047e-06, x2: 1.2868976593017578, Loss: 1.2736930433965288e-11\n",
            "Iteration 787/1000, x1: 3.923732947441749e-06, x2: 1.2868976593017578, Loss: 1.2344111843809458e-11\n",
            "Iteration 788/1000, x1: 3.862753146677278e-06, x2: 1.2868976593017578, Loss: 1.1963405960324636e-11\n",
            "Iteration 789/1000, x1: 3.802721039392054e-06, x2: 1.2868976593017578, Loss: 1.1594443287410439e-11\n",
            "Iteration 790/1000, x1: 3.743622073670849e-06, x2: 1.2868976593017578, Loss: 1.1236858665775173e-11\n",
            "Iteration 791/1000, x1: 3.6854414702247595e-06, x2: 1.2868976593017578, Loss: 1.0890303416000169e-11\n",
            "Iteration 792/1000, x1: 3.6281651318859076e-06, x2: 1.2868976593017578, Loss: 1.0554435797560657e-11\n",
            "Iteration 793/1000, x1: 3.571778961486416e-06, x2: 1.2868976593017578, Loss: 1.0228927080357941e-11\n",
            "Iteration 794/1000, x1: 3.5162690892320825e-06, x2: 1.2868976593017578, Loss: 9.913457207910703e-12\n",
            "Iteration 795/1000, x1: 3.4616218727023806e-06, x2: 1.2868976593017578, Loss: 9.60771653207848e-12\n",
            "Iteration 796/1000, x1: 3.4078238968504593e-06, x2: 1.2868976593017578, Loss: 9.311405813061668e-12\n",
            "Iteration 797/1000, x1: 3.3548619740031427e-06, x2: 1.2868976593017578, Loss: 9.024231882592826e-12\n",
            "Iteration 798/1000, x1: 3.3027231438609306e-06, x2: 1.2868976593017578, Loss: 8.745916317554059e-12\n",
            "Iteration 799/1000, x1: 3.251394673497998e-06, x2: 1.2868976593017578, Loss: 8.476183296912687e-12\n",
            "Iteration 800/1000, x1: 3.2008638299885206e-06, x2: 1.2868976593017578, Loss: 8.214769142700362e-12\n",
            "Iteration 801/1000, x1: 3.151118335154024e-06, x2: 1.2868976593017578, Loss: 7.96141711584264e-12\n",
            "Iteration 802/1000, x1: 3.1021459108160343e-06, x2: 1.2868976593017578, Loss: 7.715879150882454e-12\n",
            "Iteration 803/1000, x1: 3.0539347335434286e-06, x2: 1.2868976593017578, Loss: 7.477913253894908e-12\n",
            "Iteration 804/1000, x1: 3.0064727525314083e-06, x2: 1.2868976593017578, Loss: 7.247287405615088e-12\n",
            "Iteration 805/1000, x1: 2.959748371722526e-06, x2: 1.2868976593017578, Loss: 7.0237739235867735e-12\n",
            "Iteration 806/1000, x1: 2.913750222433009e-06, x2: 1.2868976593017578, Loss: 6.807154232651991e-12\n",
            "Iteration 807/1000, x1: 2.868466935979086e-06, x2: 1.2868976593017578, Loss: 6.5972149618231946e-12\n",
            "Iteration 808/1000, x1: 2.8238873710506596e-06, x2: 1.2868976593017578, Loss: 6.393750112687613e-12\n",
            "Iteration 809/1000, x1: 2.7800006137113087e-06, x2: 1.2868976593017578, Loss: 6.196561059407246e-12\n",
            "Iteration 810/1000, x1: 2.7367959773982875e-06, x2: 1.2868976593017578, Loss: 6.005452645591047e-12\n",
            "Iteration 811/1000, x1: 2.69426277554885e-06, x2: 1.2868976593017578, Loss: 5.8202388221462176e-12\n",
            "Iteration 812/1000, x1: 2.6523905489739263e-06, x2: 1.2868976593017578, Loss: 5.6407374431077795e-12\n",
            "Iteration 813/1000, x1: 2.611169065858121e-06, x2: 1.2868976593017578, Loss: 5.466772000362052e-12\n",
            "Iteration 814/1000, x1: 2.5705883217597147e-06, x2: 1.2868976593017578, Loss: 5.2981711899657835e-12\n",
            "Iteration 815/1000, x1: 2.5306380848633125e-06, x2: 1.2868976593017578, Loss: 5.134770646869624e-12\n",
            "Iteration 816/1000, x1: 2.491308805474546e-06, x2: 1.2868976593017578, Loss: 4.9764090417903084e-12\n",
            "Iteration 817/1000, x1: 2.4525907065253705e-06, x2: 1.2868976593017578, Loss: 4.822931550657605e-12\n",
            "Iteration 818/1000, x1: 2.4144744656950934e-06, x2: 1.2868976593017578, Loss: 4.674187686209974e-12\n",
            "Iteration 819/1000, x1: 2.376950533289346e-06, x2: 1.2868976593017578, Loss: 4.530031731675432e-12\n",
            "Iteration 820/1000, x1: 2.3400098143611103e-06, x2: 1.2868976593017578, Loss: 4.390321006048081e-12\n",
            "Iteration 821/1000, x1: 2.303643213963369e-06, x2: 1.2868976593017578, Loss: 4.2549193335350566e-12\n",
            "Iteration 822/1000, x1: 2.267841637149104e-06, x2: 1.2868976593017578, Loss: 4.123694007790446e-12\n",
            "Iteration 823/1000, x1: 2.2325964437186485e-06, x2: 1.2868976593017578, Loss: 3.996514924553551e-12\n",
            "Iteration 824/1000, x1: 2.197898993472336e-06, x2: 1.2868976593017578, Loss: 3.87325805109584e-12\n",
            "Iteration 825/1000, x1: 2.1637408735841746e-06, x2: 1.2868976593017578, Loss: 3.7538028241357324e-12\n",
            "Iteration 826/1000, x1: 2.130113671228173e-06, x2: 1.2868976593017578, Loss: 3.63803171615773e-12\n",
            "Iteration 827/1000, x1: 2.0970089735783404e-06, x2: 1.2868976593017578, Loss: 3.5258315364550263e-12\n",
            "Iteration 828/1000, x1: 2.0644188225560356e-06, x2: 1.2868976593017578, Loss: 3.417091262725158e-12\n",
            "Iteration 829/1000, x1: 2.0323352600826183e-06, x2: 1.2868976593017578, Loss: 3.3117048599956567e-12\n",
            "Iteration 830/1000, x1: 2.000750328079448e-06, x2: 1.2868976593017578, Loss: 3.2095688953792667e-12\n",
            "Iteration 831/1000, x1: 1.9696560684678843e-06, x2: 1.2868976593017578, Loss: 3.110582971754816e-12\n",
            "Iteration 832/1000, x1: 1.939045205290313e-06, x2: 1.2868976593017578, Loss: 3.0146492940863467e-12\n",
            "Iteration 833/1000, x1: 1.9089100078417687e-06, x2: 1.2868976593017578, Loss: 2.9216748378274593e-12\n",
            "Iteration 834/1000, x1: 1.8792432001646375e-06, x2: 1.2868976593017578, Loss: 2.8315674457934925e-12\n",
            "Iteration 835/1000, x1: 1.8500373926144675e-06, x2: 1.2868976593017578, Loss: 2.744239297608475e-12\n",
            "Iteration 836/1000, x1: 1.82128553660732e-06, x2: 1.2868976593017578, Loss: 2.659604090779477e-12\n",
            "Iteration 837/1000, x1: 1.7929804698724183e-06, x2: 1.2868976593017578, Loss: 2.5775794259413898e-12\n",
            "Iteration 838/1000, x1: 1.7651152575126616e-06, x2: 1.2868976593017578, Loss: 2.4980844216121456e-12\n",
            "Iteration 839/1000, x1: 1.7376831920046243e-06, x2: 1.2868976593017578, Loss: 2.4210410152353257e-12\n",
            "Iteration 840/1000, x1: 1.710677452138043e-06, x2: 1.2868976593017578, Loss: 2.346373746339725e-12\n",
            "Iteration 841/1000, x1: 1.6840913303894922e-06, x2: 1.2868976593017578, Loss: 2.2740093228584835e-12\n",
            "Iteration 842/1000, x1: 1.6579184602960595e-06, x2: 1.2868976593017578, Loss: 2.203876621129086e-12\n",
            "Iteration 843/1000, x1: 1.6321523617079947e-06, x2: 1.2868976593017578, Loss: 2.1359069027337974e-12\n",
            "Iteration 844/1000, x1: 1.6067866681623855e-06, x2: 1.2868976593017578, Loss: 2.0700335976592266e-12\n",
            "Iteration 845/1000, x1: 1.5818152405699948e-06, x2: 1.2868976593017578, Loss: 2.0061916537750246e-12\n",
            "Iteration 846/1000, x1: 1.557231826154748e-06, x2: 1.2868976593017578, Loss: 1.9443190547169253e-12\n",
            "Iteration 847/1000, x1: 1.5330305132010835e-06, x2: 1.2868976593017578, Loss: 1.8843542178015316e-12\n",
            "Iteration 848/1000, x1: 1.5092052763066022e-06, x2: 1.2868976593017578, Loss: 1.8262388129519636e-12\n",
            "Iteration 849/1000, x1: 1.4857503174425801e-06, x2: 1.2868976593017578, Loss: 1.7699159195541658e-12\n",
            "Iteration 850/1000, x1: 1.4626599522671313e-06, x2: 1.2868976593017578, Loss: 1.7153299180366899e-12\n",
            "Iteration 851/1000, x1: 1.439928382751532e-06, x2: 1.2868976593017578, Loss: 1.6624275740728667e-12\n",
            "Iteration 852/1000, x1: 1.4175500382407336e-06, x2: 1.2868976593017578, Loss: 1.6111566291179824e-12\n",
            "Iteration 853/1000, x1: 1.3955195754533634e-06, x2: 1.2868976593017578, Loss: 1.5614669930316682e-12\n",
            "Iteration 854/1000, x1: 1.373831423734373e-06, x2: 1.2868976593017578, Loss: 1.5133098767161623e-12\n",
            "Iteration 855/1000, x1: 1.3524803534892271e-06, x2: 1.2868976593017578, Loss: 1.4666377921163098e-12\n",
            "Iteration 856/1000, x1: 1.3314611351233907e-06, x2: 1.2868976593017578, Loss: 1.4214052027408663e-12\n",
            "Iteration 857/1000, x1: 1.3107685390423285e-06, x2: 1.2868976593017578, Loss: 1.3775677647209772e-12\n",
            "Iteration 858/1000, x1: 1.2903975630251807e-06, x2: 1.2868976593017578, Loss: 1.3350822183899602e-12\n",
            "Iteration 859/1000, x1: 1.2703432048510876e-06, x2: 1.2868976593017578, Loss: 1.293906930384392e-12\n",
            "Iteration 860/1000, x1: 1.2506004622991895e-06, x2: 1.2868976593017578, Loss: 1.2540016768036732e-12\n",
            "Iteration 861/1000, x1: 1.231164560522302e-06, x2: 1.2868976593017578, Loss: 1.2153271011089428e-12\n",
            "Iteration 862/1000, x1: 1.212030724673241e-06, x2: 1.2868976593017578, Loss: 1.1778451478039464e-12\n",
            "Iteration 863/1000, x1: 1.1931942935916595e-06, x2: 1.2868976593017578, Loss: 1.1415192792754714e-12\n",
            "Iteration 864/1000, x1: 1.1746506061172113e-06, x2: 1.2868976593017578, Loss: 1.1063137168518256e-12\n",
            "Iteration 865/1000, x1: 1.1563951147763873e-06, x2: 1.2868976593017578, Loss: 1.0721940913241412e-12\n",
            "Iteration 866/1000, x1: 1.1384232720956788e-06, x2: 1.2868976593017578, Loss: 1.039126684004854e-12\n",
            "Iteration 867/1000, x1: 1.1207307579752523e-06, x2: 1.2868976593017578, Loss: 1.0070789688287896e-12\n",
            "Iteration 868/1000, x1: 1.1033132523152744e-06, x2: 1.2868976593017578, Loss: 9.7601972077338e-13\n",
            "Iteration 869/1000, x1: 1.0861664350159117e-06, x2: 1.2868976593017578, Loss: 9.459183653373615e-13\n",
            "Iteration 870/1000, x1: 1.0692860996641684e-06, x2: 1.2868976593017578, Loss: 9.167454122216423e-13\n",
            "Iteration 871/1000, x1: 1.052668039847049e-06, x2: 1.2868976593017578, Loss: 8.884721300686516e-13\n",
            "Iteration 872/1000, x1: 1.036308276525233e-06, x2: 1.2868976593017578, Loss: 8.610708175128823e-13\n",
            "Iteration 873/1000, x1: 1.0202027169725625e-06, x2: 1.2868976593017578, Loss: 8.345145863404568e-13\n",
            "Iteration 874/1000, x1: 1.004347495836555e-06, x2: 1.2868976593017578, Loss: 8.087773072790183e-13\n",
            "Iteration 875/1000, x1: 9.887386340778903e-07, x2: 1.2868976593017578, Loss: 7.83833826838165e-13\n",
            "Iteration 876/1000, x1: 9.733723800309235e-07, x2: 1.2868976593017578, Loss: 7.596595336285816e-13\n",
            "Iteration 877/1000, x1: 9.582449820300099e-07, x2: 1.2868976593017578, Loss: 7.362309004631251e-13\n",
            "Iteration 878/1000, x1: 9.433526315660856e-07, x2: 1.2868976593017578, Loss: 7.135248880456302e-13\n",
            "Iteration 879/1000, x1: 9.286917475037626e-07, x2: 1.2868976593017578, Loss: 6.915189991810178e-13\n",
            "Iteration 880/1000, x1: 9.142586918642337e-07, x2: 1.2868976593017578, Loss: 6.701918750864899e-13\n",
            "Iteration 881/1000, x1: 9.000499403555295e-07, x2: 1.2868976593017578, Loss: 6.495224822399004e-13\n",
            "Iteration 882/1000, x1: 8.860620255290996e-07, x2: 1.2868976593017578, Loss: 6.294905460606237e-13\n",
            "Iteration 883/1000, x1: 8.722915367798123e-07, x2: 1.2868976593017578, Loss: 6.100764424893379e-13\n",
            "Iteration 884/1000, x1: 8.587350066591171e-07, x2: 1.2868976593017578, Loss: 5.912610895678072e-13\n",
            "Iteration 885/1000, x1: 8.453891950921388e-07, x2: 1.2868976593017578, Loss: 5.730260016489908e-13\n",
            "Iteration 886/1000, x1: 8.322508051605837e-07, x2: 1.2868976593017578, Loss: 5.553532893970425e-13\n",
            "Iteration 887/1000, x1: 8.193165967895766e-07, x2: 1.2868976593017578, Loss: 5.3822571399742e-13\n",
            "Iteration 888/1000, x1: 8.065833867476613e-07, x2: 1.2868976593017578, Loss: 5.216263618962325e-13\n",
            "Iteration 889/1000, x1: 7.940480486468005e-07, x2: 1.2868976593017578, Loss: 5.055388616406753e-13\n",
            "Iteration 890/1000, x1: 7.817075697857945e-07, x2: 1.2868976593017578, Loss: 4.899474922992475e-13\n",
            "Iteration 891/1000, x1: 7.695588806200249e-07, x2: 1.2868976593017578, Loss: 4.748370750415343e-13\n",
            "Iteration 892/1000, x1: 7.57598968448292e-07, x2: 1.2868976593017578, Loss: 4.601927020876639e-13\n",
            "Iteration 893/1000, x1: 7.45824934256234e-07, x2: 1.2868976593017578, Loss: 4.459998722335795e-13\n",
            "Iteration 894/1000, x1: 7.342338790294889e-07, x2: 1.2868976593017578, Loss: 4.322448161116904e-13\n",
            "Iteration 895/1000, x1: 7.228229605971137e-07, x2: 1.2868976593017578, Loss: 4.1891392698473195e-13\n",
            "Iteration 896/1000, x1: 7.115893936315842e-07, x2: 1.2868976593017578, Loss: 4.0599422153168863e-13\n",
            "Iteration 897/1000, x1: 7.005303928053763e-07, x2: 1.2868976593017578, Loss: 3.934729603770337e-13\n",
            "Iteration 898/1000, x1: 6.896432864778035e-07, x2: 1.2868976593017578, Loss: 3.8133786493116384e-13\n",
            "Iteration 899/1000, x1: 6.789253461647604e-07, x2: 1.2868976593017578, Loss: 3.695770902853446e-13\n",
            "Iteration 900/1000, x1: 6.683740139123984e-07, x2: 1.2868976593017578, Loss: 3.581789270561131e-13\n",
            "Iteration 901/1000, x1: 6.579866180800309e-07, x2: 1.2868976593017578, Loss: 3.4713237059141866e-13\n",
            "Iteration 902/1000, x1: 6.477606575572281e-07, x2: 1.2868976593017578, Loss: 3.3642641623921055e-13\n",
            "Iteration 903/1000, x1: 6.376936312335602e-07, x2: 1.2868976593017578, Loss: 3.260506827636872e-13\n",
            "Iteration 904/1000, x1: 6.27783094842016e-07, x2: 1.2868976593017578, Loss: 3.1599495155937296e-13\n",
            "Iteration 905/1000, x1: 6.180265472721658e-07, x2: 1.2868976593017578, Loss: 3.062493834915525e-13\n",
            "Iteration 906/1000, x1: 6.084216579438362e-07, x2: 1.2868976593017578, Loss: 2.968043291608907e-13\n",
            "Iteration 907/1000, x1: 5.989660394334351e-07, x2: 1.2868976593017578, Loss: 2.876506270590301e-13\n",
            "Iteration 908/1000, x1: 5.896573611607892e-07, x2: 1.2868976593017578, Loss: 2.787791969927761e-13\n",
            "Iteration 909/1000, x1: 5.80493349389144e-07, x2: 1.2868976593017578, Loss: 2.701813924498031e-13\n",
            "Iteration 910/1000, x1: 5.714717303817451e-07, x2: 1.2868976593017578, Loss: 2.6184872954811145e-13\n",
            "Iteration 911/1000, x1: 5.625903440886759e-07, x2: 1.2868976593017578, Loss: 2.5377304966635317e-13\n",
            "Iteration 912/1000, x1: 5.538469736166007e-07, x2: 1.2868976593017578, Loss: 2.459464381286691e-13\n",
            "Iteration 913/1000, x1: 5.452395157590217e-07, x2: 1.2868976593017578, Loss: 2.3836119709963466e-13\n",
            "Iteration 914/1000, x1: 5.367658104660222e-07, x2: 1.2868976593017578, Loss: 2.3100992689942257e-13\n",
            "Iteration 915/1000, x1: 5.284238113745232e-07, x2: 1.2868976593017578, Loss: 2.2388534982095004e-13\n",
            "Iteration 916/1000, x1: 5.202114721214457e-07, x2: 1.2868976593017578, Loss: 2.1698051341778601e-13\n",
            "Iteration 917/1000, x1: 5.121267463437107e-07, x2: 1.2868976593017578, Loss: 2.102886549788796e-13\n",
            "Iteration 918/1000, x1: 5.041676445216581e-07, x2: 1.2868976593017578, Loss: 2.038031473184515e-13\n",
            "Iteration 919/1000, x1: 4.963322339790466e-07, x2: 1.2868976593017578, Loss: 1.9751766140631982e-13\n",
            "Iteration 920/1000, x1: 4.886185820396349e-07, x2: 1.2868976593017578, Loss: 1.914260172901014e-13\n",
            "Iteration 921/1000, x1: 4.810248128706007e-07, x2: 1.2868976593017578, Loss: 1.8552222475279323e-13\n",
            "Iteration 922/1000, x1: 4.73549079060831e-07, x2: 1.2868976593017578, Loss: 1.79800523970354e-13\n",
            "Iteration 923/1000, x1: 4.6618953319921275e-07, x2: 1.2868976593017578, Loss: 1.7425529064401396e-13\n",
            "Iteration 924/1000, x1: 4.5894435629634245e-07, x2: 1.2868976593017578, Loss: 1.688810902103835e-13\n",
            "Iteration 925/1000, x1: 4.518117862062354e-07, x2: 1.2868976593017578, Loss: 1.636726236313446e-13\n",
            "Iteration 926/1000, x1: 4.4479006078290695e-07, x2: 1.2868976593017578, Loss: 1.5862480870921375e-13\n",
            "Iteration 927/1000, x1: 4.3787747472379124e-07, x2: 1.2868976593017578, Loss: 1.537326581139975e-13\n",
            "Iteration 928/1000, x1: 4.3107232272632245e-07, x2: 1.2868976593017578, Loss: 1.4899140135613692e-13\n",
            "Iteration 929/1000, x1: 4.243729279096442e-07, x2: 1.2868976593017578, Loss: 1.4439636281376317e-13\n",
            "Iteration 930/1000, x1: 4.177776418146095e-07, x2: 1.2868976593017578, Loss: 1.3994304304786043e-13\n",
            "Iteration 931/1000, x1: 4.112848444037809e-07, x2: 1.2868976593017578, Loss: 1.3562706459215729e-13\n",
            "Iteration 932/1000, x1: 4.048929724831396e-07, x2: 1.2868976593017578, Loss: 1.314441855056539e-13\n",
            "Iteration 933/1000, x1: 3.986004344369576e-07, x2: 1.2868976593017578, Loss: 1.2739032647767629e-13\n",
            "Iteration 934/1000, x1: 3.924056954929256e-07, x2: 1.2868976593017578, Loss: 1.234614895127134e-13\n",
            "Iteration 935/1000, x1: 3.8630722087873437e-07, x2: 1.2868976593017578, Loss: 1.1965382569305294e-13\n",
            "Iteration 936/1000, x1: 3.8030353266549355e-07, x2: 1.2868976593017578, Loss: 1.159635945211998e-13\n",
            "Iteration 937/1000, x1: 3.7439315292431274e-07, x2: 1.2868976593017578, Loss: 1.1238716391987619e-13\n",
            "Iteration 938/1000, x1: 3.685746037263016e-07, x2: 1.2868976593017578, Loss: 1.0892104411333939e-13\n",
            "Iteration 939/1000, x1: 3.6284649240769795e-07, x2: 1.2868976593017578, Loss: 1.0556180631221893e-13\n",
            "Iteration 940/1000, x1: 3.5720739788303035e-07, x2: 1.2868976593017578, Loss: 1.0230617758120661e-13\n",
            "Iteration 941/1000, x1: 3.516559559102461e-07, x2: 1.2868976593017578, Loss: 9.915094597136645e-14\n",
            "Iteration 942/1000, x1: 3.4619077382558316e-07, x2: 1.2868976593017578, Loss: 9.609304861156118e-14\n",
            "Iteration 943/1000, x1: 3.408105442304077e-07, x2: 1.2868976593017578, Loss: 9.31294294069171e-14\n",
            "Iteration 944/1000, x1: 3.3551393130437646e-07, x2: 1.2868976593017578, Loss: 9.025723555046786e-14\n",
            "Iteration 945/1000, x1: 3.302996276488557e-07, x2: 1.2868976593017578, Loss: 8.747362101151068e-14\n",
            "Iteration 946/1000, x1: 3.25166354286921e-07, x2: 1.2868976593017578, Loss: 8.477584817956005e-14\n",
            "Iteration 947/1000, x1: 3.201128606633574e-07, x2: 1.2868976593017578, Loss: 8.21612810880841e-14\n",
            "Iteration 948/1000, x1: 3.151378962229501e-07, x2: 1.2868976593017578, Loss: 7.962734475692318e-14\n",
            "Iteration 949/1000, x1: 3.1024026725390286e-07, x2: 1.2868976593017578, Loss: 7.717155907360773e-14\n",
            "Iteration 950/1000, x1: 3.0541875162271026e-07, x2: 1.2868976593017578, Loss: 7.479151168830397e-14\n",
            "Iteration 951/1000, x1: 3.006721556175762e-07, x2: 1.2868976593017578, Loss: 7.248487156634106e-14\n",
            "Iteration 952/1000, x1: 2.959993423701235e-07, x2: 1.2868976593017578, Loss: 7.024936865942036e-14\n",
            "Iteration 953/1000, x1: 2.9139914659026545e-07, x2: 1.2868976593017578, Loss: 6.808281423440615e-14\n",
            "Iteration 954/1000, x1: 2.8687043140962487e-07, x2: 1.2868976593017578, Loss: 6.598307376827137e-14\n",
            "Iteration 955/1000, x1: 2.824121168032434e-07, x2: 1.2868976593017578, Loss: 6.394808727688828e-14\n",
            "Iteration 956/1000, x1: 2.7802306590274384e-07, x2: 1.2868976593017578, Loss: 6.197586931502852e-14\n",
            "Iteration 957/1000, x1: 2.7370222710487724e-07, x2: 1.2868976593017578, Loss: 6.006446831878162e-14\n",
            "Iteration 958/1000, x1: 2.694485488063947e-07, x2: 1.2868976593017578, Loss: 5.821201403940005e-14\n",
            "Iteration 959/1000, x1: 2.6526097940404725e-07, x2: 1.2868976593017578, Loss: 5.6416700602640243e-14\n",
            "Iteration 960/1000, x1: 2.6113849571629544e-07, x2: 1.2868976593017578, Loss: 5.467675262744477e-14\n",
            "Iteration 961/1000, x1: 2.5708007456159976e-07, x2: 1.2868976593017578, Loss: 5.299047265978733e-14\n",
            "Iteration 962/1000, x1: 2.5308472118013015e-07, x2: 1.2868976593017578, Loss: 5.135619373882773e-14\n",
            "Iteration 963/1000, x1: 2.4915146923376597e-07, x2: 1.2868976593017578, Loss: 4.9772316666361546e-14\n",
            "Iteration 964/1000, x1: 2.452793523843866e-07, x2: 1.2868976593017578, Loss: 4.823728967802941e-14\n",
            "Iteration 965/1000, x1: 2.4146740429387137e-07, x2: 1.2868976593017578, Loss: 4.674960505518522e-14\n",
            "Iteration 966/1000, x1: 2.3771470125666383e-07, x2: 1.2868976593017578, Loss: 4.530780590115968e-14\n",
            "Iteration 967/1000, x1: 2.3402031956720748e-07, x2: 1.2868976593017578, Loss: 4.391046920060142e-14\n",
            "Iteration 968/1000, x1: 2.3038334973080055e-07, x2: 1.2868976593017578, Loss: 4.2556229536399454e-14\n",
            "Iteration 969/1000, x1: 2.2680291067445069e-07, x2: 1.2868976593017578, Loss: 4.1243751984628915e-14\n",
            "Iteration 970/1000, x1: 2.2327810711431084e-07, x2: 1.2868976593017578, Loss: 3.9971755831473554e-14\n",
            "Iteration 971/1000, x1: 2.198080863990981e-07, x2: 1.2868976593017578, Loss: 3.8738987468171435e-14\n",
            "Iteration 972/1000, x1: 2.1639199587752955e-07, x2: 1.2868976593017578, Loss: 3.7544240719805666e-14\n",
            "Iteration 973/1000, x1: 2.13028997109177e-07, x2: 1.2868976593017578, Loss: 3.638633990464546e-14\n",
            "Iteration 974/1000, x1: 2.0971826586446696e-07, x2: 1.2868976593017578, Loss: 3.5264149998541494e-14\n",
            "Iteration 975/1000, x1: 2.0645897791382595e-07, x2: 1.2868976593017578, Loss: 3.417657324679413e-14\n",
            "Iteration 976/1000, x1: 2.0325035166024463e-07, x2: 1.2868976593017578, Loss: 3.3122532223494455e-14\n",
            "Iteration 977/1000, x1: 2.0009159129585896e-07, x2: 1.2868976593017578, Loss: 3.210100371284219e-14\n",
            "Iteration 978/1000, x1: 1.969819152236596e-07, x2: 1.2868976593017578, Loss: 3.111097805156421e-14\n",
            "Iteration 979/1000, x1: 1.9392057026834664e-07, x2: 1.2868976593017578, Loss: 3.015148284583706e-14\n",
            "Iteration 980/1000, x1: 1.9090680325462017e-07, x2: 1.2868976593017578, Loss: 2.922158297128698e-14\n",
            "Iteration 981/1000, x1: 1.87939875218035e-07, x2: 1.2868976593017578, Loss: 2.8320363632330925e-14\n",
            "Iteration 982/1000, x1: 1.8501906140500068e-07, x2: 1.2868976593017578, Loss: 2.744693375030839e-14\n",
            "Iteration 983/1000, x1: 1.821436370619267e-07, x2: 1.2868976593017578, Loss: 2.6600447986338017e-14\n",
            "Iteration 984/1000, x1: 1.7931289164607733e-07, x2: 1.2868976593017578, Loss: 2.5780064389670232e-14\n",
            "Iteration 985/1000, x1: 1.7652614303642622e-07, x2: 1.2868976593017578, Loss: 2.4984979973071038e-14\n",
            "Iteration 986/1000, x1: 1.7378270911194704e-07, x2: 1.2868976593017578, Loss: 2.421441885436075e-14\n",
            "Iteration 987/1000, x1: 1.7108190775161347e-07, x2: 1.2868976593017578, Loss: 2.3467623786084524e-14\n",
            "Iteration 988/1000, x1: 1.684230852561086e-07, x2: 1.2868976593017578, Loss: 2.2743859543644142e-14\n",
            "Iteration 989/1000, x1: 1.6580557371526083e-07, x2: 1.2868976593017578, Loss: 2.20424180074957e-14\n",
            "Iteration 990/1000, x1: 1.6322874785146269e-07, x2: 1.2868976593017578, Loss: 2.1362606304688343e-14\n",
            "Iteration 991/1000, x1: 1.6069196817625198e-07, x2: 1.2868976593017578, Loss: 2.0703763749523214e-14\n",
            "Iteration 992/1000, x1: 1.5819460941202124e-07, x2: 1.2868976593017578, Loss: 2.0065238126630927e-14\n",
            "Iteration 993/1000, x1: 1.5573606049201771e-07, x2: 1.2868976593017578, Loss: 1.9446406019762302e-14\n",
            "Iteration 994/1000, x1: 1.5331572456034337e-07, x2: 1.2868976593017578, Loss: 1.884665925926121e-14\n",
            "Iteration 995/1000, x1: 1.5093300476110016e-07, x2: 1.2868976593017578, Loss: 1.8265408310196365e-14\n",
            "Iteration 996/1000, x1: 1.4858731844924478e-07, x2: 1.2868976593017578, Loss: 1.7702085660493104e-14\n",
            "Iteration 997/1000, x1: 1.4627808297973388e-07, x2: 1.2868976593017578, Loss: 1.7156135656538028e-14\n",
            "Iteration 998/1000, x1: 1.4400474412923359e-07, x2: 1.2868976593017578, Loss: 1.6627022973508473e-14\n",
            "Iteration 999/1000, x1: 1.4176673346355528e-07, x2: 1.2868976593017578, Loss: 1.6114230921306615e-14\n",
            "Iteration 1000/1000, x1: 1.3956349675936508e-07, x2: 1.2868976593017578, Loss: 1.5617252974229993e-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.exp(z)\n",
        "final_result = (x1.item(), x2.item())\n",
        "print(f'Optimal solution: x1 = {final_result[0]}, x2 = {final_result[1]}, Minimum value: {objective(*final_result)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl8oEOeUSZHX",
        "outputId": "4da6a882-7e22-4893-f7d7-36265b8aa791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal solution: x1 = 1.3956349675936508e-07, x2 = 1.2868976593017578, Minimum value: 1.5135601099989274e-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Classify MNIST Dataset with MyGD Optimizer"
      ],
      "metadata": {
        "id": "YS7wMHgQSeSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "hezp4gcmS05u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load MNIST dataset"
      ],
      "metadata": {
        "id": "Hos0a6zUTCp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "HLSzcMXgTIwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Network"
      ],
      "metadata": {
        "id": "Kv_sD-q2S2Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "MYXp1LOpS8mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyNet()\n",
        "optimizer = MyGD(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "21tI0i20MOHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "kQkpZH1qTTqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = []\n",
        "\n",
        "for epoch in range(20):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    loss_values.append(loss.item())\n",
        "\n",
        "        # Print the loss\n",
        "    print(f'Epoch [{epoch + 1}/{20}], Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMzxMWVCTV80",
        "outputId": "d968eaa3-ebec-47fa-e5c6-e6472b4b2cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 2.053619384765625\n",
            "Epoch [2/20], Loss: 1.6897128820419312\n",
            "Epoch [3/20], Loss: 0.949285089969635\n",
            "Epoch [4/20], Loss: 0.7740514874458313\n",
            "Epoch [5/20], Loss: 0.7070786952972412\n",
            "Epoch [6/20], Loss: 0.6551414728164673\n",
            "Epoch [7/20], Loss: 0.5353940725326538\n",
            "Epoch [8/20], Loss: 0.4001172184944153\n",
            "Epoch [9/20], Loss: 0.40212804079055786\n",
            "Epoch [10/20], Loss: 0.2390829473733902\n",
            "Epoch [11/20], Loss: 0.311837762594223\n",
            "Epoch [12/20], Loss: 0.2997358441352844\n",
            "Epoch [13/20], Loss: 0.4211260676383972\n",
            "Epoch [14/20], Loss: 0.27513355016708374\n",
            "Epoch [15/20], Loss: 0.2037477344274521\n",
            "Epoch [16/20], Loss: 0.3633786737918854\n",
            "Epoch [17/20], Loss: 0.1400723159313202\n",
            "Epoch [18/20], Loss: 0.1475607454776764\n",
            "Epoch [19/20], Loss: 0.25815147161483765\n",
            "Epoch [20/20], Loss: 0.23419153690338135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.errorbar(range(1, len(loss_values) + 1), loss_values, fmt='-', yerr=None, ecolor='red', capsize=5)\n",
        "plt.title('Training Loss with Error Bars')\n",
        "plt.xlabel('Training Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OWLyCUvDZRY9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "bf185ad7-0040-444d-c32f-ecbe40af64a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Model"
      ],
      "metadata": {
        "id": "MsBtDncHTh38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {100 * accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "ku9rlWqiTjpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e9a6b2-cbdd-49cf-b929-b58e7582cc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 91.01%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eN5F-VOMPcW9",
        "GcvYFbdhQEDN",
        "U5pJq7QafSQ7",
        "MX79YKeJeOEu",
        "YA4FAESJeicC",
        "PQUsGxVYeqn5"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}